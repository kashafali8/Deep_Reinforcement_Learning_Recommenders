{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOFBaKZytjsk2/ivPmhm9ID",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kashafali8/Deep_Reinforcement_Learning_Recommenders/blob/main/DRL_Recommenders/Dataset_RR/SNQN_RR_ItemFeatures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9mVbskCUGZ8",
        "outputId": "6c53f900-f7ed-4ab6-f5cc-ddb09142603c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -R /content/Deep_Reinforcement_Learning_Recommenders\n",
        "!git clone https://github.com/kashafali8/Deep_Reinforcement_Learning_Recommenders.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnPws2sNUcvO",
        "outputId": "0a61758b-8e50-43c0-cde2-b7be05a6c980"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/Deep_Reinforcement_Learning_Recommenders': No such file or directory\n",
            "Cloning into 'Deep_Reinforcement_Learning_Recommenders'...\n",
            "remote: Enumerating objects: 437, done.\u001b[K\n",
            "remote: Counting objects: 100% (187/187), done.\u001b[K\n",
            "remote: Compressing objects: 100% (124/124), done.\u001b[K\n",
            "remote: Total 437 (delta 123), reused 115 (delta 59), pack-reused 250\u001b[K\n",
            "Receiving objects: 100% (437/437), 8.49 MiB | 17.11 MiB/s, done.\n",
            "Resolving deltas: 100% (235/235), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install trfl\n",
        "!pip install kaggle"
      ],
      "metadata": {
        "id": "ZHWqg6LnUfH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/drive/MyDrive/kaggle.json /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "uYk85JHZUhFx"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d retailrocket/ecommerce-dataset\n",
        "!unzip ecommerce-dataset.zip -d Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/data/\n",
        "!rm ecommerce-dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Wrl71vlUjSm",
        "outputId": "60082e33-4bfd-46f6-a4f3-368660f8a248"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ecommerce-dataset.zip to /content\n",
            "100% 291M/291M [00:14<00:00, 23.3MB/s]\n",
            "100% 291M/291M [00:14<00:00, 21.2MB/s]\n",
            "Archive:  ecommerce-dataset.zip\n",
            "  inflating: Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/data/category_tree.csv  \n",
            "  inflating: Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/data/events.csv  \n",
            "  inflating: Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/data/item_properties_part1.csv  \n",
            "  inflating: Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/data/item_properties_part2.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/replay_buffer.py --data /content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2vcj331UlAz",
        "outputId": "2862bc0c-aafe-4d8a-f1d7-a8a9c6cefbbf"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting to pre-process data...\n",
            "\n",
            "Sorting and pickling data...\n",
            "\n",
            "Splitting data into train, validation, and test sets...\n",
            "\n",
            "Pickling train, validation, and test sets...\n",
            "\n",
            "Calculating item popularity and storing as dictionary...\n",
            "\n",
            "Generating replay buffer from train set...\n",
            "\n",
            "Pickling replay buffer...\n",
            "\n",
            "Pickling data statistics...\n",
            "\n",
            "Script completed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "S4sg8yU7Um_c"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ip_df = pd.read_csv(\"/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/data/item_properties_part1.csv\")"
      ],
      "metadata": {
        "id": "ulH6Met7UpBv"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ip_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "z9MzCe54XeXW",
        "outputId": "1cdeb2d0-9195-4544-fb0c-2bf9ba1daf1d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              timestamp  itemid    property                            value\n",
              "0         1435460400000  460429  categoryid                             1338\n",
              "1         1441508400000  206783         888          1116713 960601 n277.200\n",
              "2         1439089200000  395014         400  n552.000 639502 n720.000 424566\n",
              "3         1431226800000   59481         790                       n15360.000\n",
              "4         1431831600000  156781         917                           828513\n",
              "...                 ...     ...         ...                              ...\n",
              "10999994  1439694000000   86599  categoryid                              618\n",
              "10999995  1435460400000  153032        1066                 n1020.000 424566\n",
              "10999996  1440298800000  421788         888               35975 856003 37346\n",
              "10999997  1437879600000  159792         400  n552.000 639502 n720.000 424566\n",
              "10999998  1436065200000  464846         790                      n410640.000\n",
              "\n",
              "[10999999 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-80c10013-6025-4608-ac1b-e348d9eabe1f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>itemid</th>\n",
              "      <th>property</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1435460400000</td>\n",
              "      <td>460429</td>\n",
              "      <td>categoryid</td>\n",
              "      <td>1338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1441508400000</td>\n",
              "      <td>206783</td>\n",
              "      <td>888</td>\n",
              "      <td>1116713 960601 n277.200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1439089200000</td>\n",
              "      <td>395014</td>\n",
              "      <td>400</td>\n",
              "      <td>n552.000 639502 n720.000 424566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1431226800000</td>\n",
              "      <td>59481</td>\n",
              "      <td>790</td>\n",
              "      <td>n15360.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1431831600000</td>\n",
              "      <td>156781</td>\n",
              "      <td>917</td>\n",
              "      <td>828513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10999994</th>\n",
              "      <td>1439694000000</td>\n",
              "      <td>86599</td>\n",
              "      <td>categoryid</td>\n",
              "      <td>618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10999995</th>\n",
              "      <td>1435460400000</td>\n",
              "      <td>153032</td>\n",
              "      <td>1066</td>\n",
              "      <td>n1020.000 424566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10999996</th>\n",
              "      <td>1440298800000</td>\n",
              "      <td>421788</td>\n",
              "      <td>888</td>\n",
              "      <td>35975 856003 37346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10999997</th>\n",
              "      <td>1437879600000</td>\n",
              "      <td>159792</td>\n",
              "      <td>400</td>\n",
              "      <td>n552.000 639502 n720.000 424566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10999998</th>\n",
              "      <td>1436065200000</td>\n",
              "      <td>464846</td>\n",
              "      <td>790</td>\n",
              "      <td>n410640.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10999999 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80c10013-6025-4608-ac1b-e348d9eabe1f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-80c10013-6025-4608-ac1b-e348d9eabe1f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-80c10013-6025-4608-ac1b-e348d9eabe1f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def create_feature_matrix(\n",
        "    sorted_events, n_files=2, path_name=\"\", one_hot_encode=True, top_features=500\n",
        "):\n",
        "    for i in range(n_files):\n",
        "        if i == 0:\n",
        "            item_features = pd.read_csv(path_name + str(i + 1) + \".csv\")\n",
        "        else:\n",
        "            item_features = pd.concat(\n",
        "                [item_features, pd.read_csv(path_name + str(i + 1) + \".csv\")],\n",
        "                ignore_index=True,\n",
        "            )\n",
        "\n",
        "    item_features = item_features[\n",
        "        item_features[\"itemid\"].isin(sorted_events[\"item_id\"].unique().tolist())\n",
        "    ].drop_duplicates()\n",
        "    item_features[\"property_value\"] = (\n",
        "        item_features[\"property\"].str.strip() + item_features[\"value\"].str.strip()\n",
        "    )\n",
        "    item_features = item_features.drop([\"timestamp\"], axis=1).drop_duplicates()\n",
        "\n",
        "    if one_hot_encode:\n",
        "        one_hot_encoded = pd.DataFrame()\n",
        "        itemids = []\n",
        "\n",
        "        event_item_list = sorted_events.item_id.unique()\n",
        "        event_item_list.sort()\n",
        "        item_list = item_features[\"itemid\"].unique()\n",
        "        properties = (\n",
        "            item_features[\"property_value\"]\n",
        "            .value_counts()\n",
        "            .head(top_features)\n",
        "            .index.tolist()\n",
        "        )\n",
        "\n",
        "        for item in event_item_list:\n",
        "            if len(itemids) % 1000 == 0:\n",
        "                print(\"hi\")\n",
        "            if item not in item_list:\n",
        "                one_hot_encoded = pd.concat(\n",
        "                    [one_hot_encoded, pd.DataFrame(np.zeros(len(properties))).T],\n",
        "                    ignore_index=True,\n",
        "                )\n",
        "                itemids.append(item)\n",
        "                continue\n",
        "\n",
        "            item_properties = item_features[item_features[\"itemid\"] == item][\n",
        "                \"property_value\"\n",
        "            ].unique()\n",
        "            one_hot_encoded = pd.concat(\n",
        "                [\n",
        "                    one_hot_encoded,\n",
        "                    pd.DataFrame(\n",
        "                        [1 if x in item_properties else 0 for x in properties]\n",
        "                    ).T,\n",
        "                ],\n",
        "                ignore_index=True,\n",
        "            )\n",
        "            itemids.append(item)\n",
        "\n",
        "        return one_hot_encoded, itemids\n",
        "\n",
        "    else:\n",
        "        return item_features, item_features[\"itemid\"].unique().tolist()"
      ],
      "metadata": {
        "id": "r7GFz27zXklJ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_events = pd.read_pickle(\"/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/data/sorted_events.df\")\n",
        "one_hot_encoded, itemids = create_feature_matrix(\n",
        "    sorted_events, n_files=2, path_name=\"/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/data/item_properties_part\", one_hot_encode=True\n",
        ")"
      ],
      "metadata": {
        "id": "8rdVnFOocHuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_encoded.to_pickle(\"/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/data/one_hot_encoded.df\")"
      ],
      "metadata": {
        "id": "iD_rIhqLreex"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python \"/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/SNQN_IF.py\" --model=SASRec --epoch=10 --data=\"/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/data/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8wOsWNDdzro",
        "outputId": "4021978f-0786-4d7b-ab31-3dcf8c975a0f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-04 03:21:03.050822: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-05-04 03:21:03.103901: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-04 03:21:04.124652: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/SNQN_IF.py:185: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
            "  self.seq = tf.compat.v1.layers.dropout(self.seq,\n",
            "2023-05-04 03:21:07.342958: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n",
            "\t [[{{node Placeholder}}]]\n",
            "/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/SASRecModules.py:142: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  Q = tf.compat.v1.layers.dense(queries, num_units, activation=None) # (N, T_q, C)\n",
            "/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/SASRecModules.py:143: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  K = tf.compat.v1.layers.dense(keys, num_units, activation=None) # (N, T_k, C)\n",
            "/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/SASRecModules.py:144: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  V = tf.compat.v1.layers.dense(keys, num_units, activation=None) # (N, T_k, C)\n",
            "/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/SASRecModules.py:184: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
            "  outputs = tf.compat.v1.layers.dropout(outputs, rate=dropout_rate, training=tf.convert_to_tensor(value=is_training))\n",
            "2023-05-04 03:21:07.561091: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n",
            "\t [[{{node Placeholder}}]]\n",
            "/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/SASRecModules.py:223: UserWarning: `tf.layers.conv1d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv1D` instead.\n",
            "  outputs = tf.compat.v1.layers.conv1d(**params)\n",
            "/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/SASRecModules.py:224: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
            "  outputs = tf.compat.v1.layers.dropout(outputs, rate=dropout_rate, training=tf.convert_to_tensor(value=is_training))\n",
            "2023-05-04 03:21:07.618646: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n",
            "\t [[{{node Placeholder}}]]\n",
            "/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/SASRecModules.py:228: UserWarning: `tf.layers.conv1d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv1D` instead.\n",
            "  outputs = tf.compat.v1.layers.conv1d(**params)\n",
            "/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/SASRecModules.py:229: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
            "  outputs = tf.compat.v1.layers.dropout(outputs, rate=dropout_rate, training=tf.convert_to_tensor(value=is_training))\n",
            "2023-05-04 03:21:07.659412: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n",
            "\t [[{{node Placeholder}}]]\n",
            "/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/SNQN_IF.py:213: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n",
            "/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/SNQN_IF.py:216: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output2= tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n",
            "/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/SNQN_IF.py:228: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.w_f = tf.compat.v1.layers.dense(\n",
            "w_f SHAPE:  (70852, 64)\n",
            "phi 2 SHAPE:  (None, 70852)\n",
            "/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/SNQN_IF.py:185: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
            "  self.seq = tf.compat.v1.layers.dropout(self.seq,\n",
            "2023-05-04 03:21:10.596844: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n",
            "\t [[{{node Placeholder_1}}]]\n",
            "/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/SASRecModules.py:142: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  Q = tf.compat.v1.layers.dense(queries, num_units, activation=None) # (N, T_q, C)\n",
            "/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/SASRecModules.py:143: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  K = tf.compat.v1.layers.dense(keys, num_units, activation=None) # (N, T_k, C)\n",
            "/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/SASRecModules.py:144: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  V = tf.compat.v1.layers.dense(keys, num_units, activation=None) # (N, T_k, C)\n",
            "/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/SASRecModules.py:184: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
            "  outputs = tf.compat.v1.layers.dropout(outputs, rate=dropout_rate, training=tf.convert_to_tensor(value=is_training))\n",
            "2023-05-04 03:21:10.750502: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n",
            "\t [[{{node Placeholder_1}}]]\n",
            "/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/SASRecModules.py:223: UserWarning: `tf.layers.conv1d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv1D` instead.\n",
            "  outputs = tf.compat.v1.layers.conv1d(**params)\n",
            "/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/SASRecModules.py:224: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
            "  outputs = tf.compat.v1.layers.dropout(outputs, rate=dropout_rate, training=tf.convert_to_tensor(value=is_training))\n",
            "2023-05-04 03:21:10.808610: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n",
            "\t [[{{node Placeholder_1}}]]\n",
            "/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/SASRecModules.py:228: UserWarning: `tf.layers.conv1d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv1D` instead.\n",
            "  outputs = tf.compat.v1.layers.conv1d(**params)\n",
            "/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/SASRecModules.py:229: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
            "  outputs = tf.compat.v1.layers.dropout(outputs, rate=dropout_rate, training=tf.convert_to_tensor(value=is_training))\n",
            "2023-05-04 03:21:10.853164: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n",
            "\t [[{{node Placeholder_1}}]]\n",
            "/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/SNQN_IF.py:213: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n",
            "/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/SNQN_IF.py:216: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output2= tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n",
            "/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/SNQN_IF.py:228: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.w_f = tf.compat.v1.layers.dense(\n",
            "w_f SHAPE:  (70852, 64)\n",
            "phi 2 SHAPE:  (None, 70852)\n",
            "2023-05-04 03:21:17.695976: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-05-04 03:21:17.696060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38286 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n",
            "2023-05-04 03:21:18.832998: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
            "2023-05-04 03:21:25.341801: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
            "2023-05-04 03:21:44.234119: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8700\n",
            "the loss in 200th batch is: 11.071962\n",
            "the loss in 400th batch is: 10.750019\n",
            "the loss in 600th batch is: 10.634927\n",
            "the loss in 800th batch is: 10.408591\n",
            "the loss in 1000th batch is: 10.404018\n",
            "the loss in 1200th batch is: 10.407974\n",
            "the loss in 1400th batch is: 10.000029\n",
            "the loss in 1600th batch is: 10.253592\n",
            "the loss in 1800th batch is: 10.152149\n",
            "the loss in 2000th batch is: 10.110633\n",
            "the loss in 2200th batch is: 9.928721\n",
            "the loss in 2400th batch is: 9.959167\n",
            "the loss in 2600th batch is: 9.788565\n",
            "the loss in 2800th batch is: 10.148671\n",
            "the loss in 3000th batch is: 9.980742\n",
            "the loss in 3200th batch is: 9.760844\n",
            "the loss in 3400th batch is: 9.885682\n",
            "the loss in 3600th batch is: 9.576026\n",
            "the loss in 3800th batch is: 9.278900\n",
            "the loss in 4000th batch is: 9.540248\n",
            "#############################################################\n",
            "total clicks: 117015, total purchase:5578\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 69.000000\n",
            "clicks hr ndcg @ 5 : 0.001666, 0.001107\n",
            "purchase hr and ndcg @5 : 0.005378, 0.003937\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 92.200000\n",
            "clicks hr ndcg @ 10 : 0.002188, 0.001275\n",
            "purchase hr and ndcg @10 : 0.007350, 0.004587\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 112.400000\n",
            "clicks hr ndcg @ 15 : 0.002666, 0.001401\n",
            "purchase hr and ndcg @15 : 0.008964, 0.005011\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 125.800000\n",
            "clicks hr ndcg @ 20 : 0.003025, 0.001486\n",
            "purchase hr and ndcg @20 : 0.009860, 0.005219\n",
            "#############################################################\n",
            "the loss in 4200th batch is: 9.104990\n",
            "the loss in 4400th batch is: 9.176187\n",
            "the loss in 4600th batch is: 8.799990\n",
            "the loss in 4800th batch is: 9.260778\n",
            "the loss in 5000th batch is: 8.811574\n",
            "the loss in 5200th batch is: 9.418615\n",
            "the loss in 5400th batch is: 8.955151\n",
            "the loss in 5600th batch is: 8.843449\n",
            "the loss in 5800th batch is: 8.883937\n",
            "the loss in 6000th batch is: 8.799519\n",
            "the loss in 6200th batch is: 9.156127\n",
            "the loss in 6400th batch is: 8.981112\n",
            "the loss in 6600th batch is: 8.804762\n",
            "the loss in 6800th batch is: 8.736623\n",
            "the loss in 7200th batch is: 8.235170\n",
            "the loss in 7400th batch is: 8.431317\n",
            "the loss in 7600th batch is: 8.246764\n",
            "the loss in 7800th batch is: 8.342558\n",
            "the loss in 8000th batch is: 8.657604\n",
            "#############################################################\n",
            "total clicks: 117015, total purchase:5578\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 59.400000\n",
            "clicks hr ndcg @ 5 : 0.001128, 0.000743\n",
            "purchase hr and ndcg @5 : 0.005916, 0.004231\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 90.000000\n",
            "clicks hr ndcg @ 10 : 0.001666, 0.000915\n",
            "purchase hr and ndcg @10 : 0.009143, 0.005297\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 107.000000\n",
            "clicks hr ndcg @ 15 : 0.002136, 0.001038\n",
            "purchase hr and ndcg @15 : 0.010219, 0.005577\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 121.400000\n",
            "clicks hr ndcg @ 20 : 0.002495, 0.001123\n",
            "purchase hr and ndcg @20 : 0.011294, 0.005832\n",
            "#############################################################\n",
            "the loss in 8200th batch is: 8.195477\n",
            "the loss in 8400th batch is: 8.320519\n",
            "the loss in 8600th batch is: 8.374553\n",
            "the loss in 8800th batch is: 8.102221\n",
            "the loss in 9000th batch is: 8.393150\n",
            "the loss in 9200th batch is: 8.117598\n",
            "the loss in 9400th batch is: 8.072386\n",
            "the loss in 9600th batch is: 8.182747\n",
            "the loss in 9800th batch is: 7.612730\n",
            "the loss in 10000th batch is: 7.504498\n",
            "the loss in 10200th batch is: 7.426636\n",
            "the loss in 10400th batch is: 7.942306\n",
            "the loss in 10600th batch is: 7.387358\n",
            "the loss in 10800th batch is: 7.812089\n",
            "the loss in 11000th batch is: 7.062674\n",
            "the loss in 11200th batch is: 7.817523\n",
            "the loss in 11400th batch is: 7.708543\n",
            "the loss in 11600th batch is: 7.516217\n",
            "the loss in 11800th batch is: 7.661252\n",
            "the loss in 12000th batch is: 7.460234\n",
            "#############################################################\n",
            "total clicks: 117015, total purchase:5578\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 39.000000\n",
            "clicks hr ndcg @ 5 : 0.000855, 0.000553\n",
            "purchase hr and ndcg @5 : 0.003406, 0.002555\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 61.400000\n",
            "clicks hr ndcg @ 10 : 0.001342, 0.000710\n",
            "purchase hr and ndcg @10 : 0.005378, 0.003195\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 86.400000\n",
            "clicks hr ndcg @ 15 : 0.001769, 0.000822\n",
            "purchase hr and ndcg @15 : 0.008067, 0.003897\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 101.200000\n",
            "clicks hr ndcg @ 20 : 0.002060, 0.000891\n",
            "purchase hr and ndcg @20 : 0.009502, 0.004234\n",
            "#############################################################\n",
            "the loss in 12200th batch is: 7.303171\n",
            "the loss in 12400th batch is: 7.542130\n",
            "the loss in 12600th batch is: 7.481812\n",
            "the loss in 12800th batch is: 7.344527\n",
            "the loss in 13000th batch is: 6.911525\n",
            "the loss in 13200th batch is: 7.378940\n",
            "the loss in 13400th batch is: 7.493867\n",
            "the loss in 13600th batch is: 7.596643\n",
            "the loss in 13800th batch is: 7.392413\n",
            "the loss in 14000th batch is: 7.308137\n",
            "the loss in 14200th batch is: 7.399618\n",
            "the loss in 14400th batch is: 7.289553\n",
            "the loss in 14600th batch is: 6.928010\n",
            "the loss in 14800th batch is: 7.372972\n",
            "the loss in 15000th batch is: 6.952129\n",
            "the loss in 15200th batch is: 7.181691\n",
            "the loss in 15400th batch is: 7.225537\n",
            "the loss in 15600th batch is: 7.534161\n",
            "the loss in 15800th batch is: 6.731313\n",
            "the loss in 16000th batch is: 7.276655\n",
            "#############################################################\n",
            "total clicks: 117015, total purchase:5578\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 59.400000\n",
            "clicks hr ndcg @ 5 : 0.001214, 0.000871\n",
            "purchase hr and ndcg @5 : 0.005558, 0.003980\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 83.200000\n",
            "clicks hr ndcg @ 10 : 0.001718, 0.001032\n",
            "purchase hr and ndcg @10 : 0.007709, 0.004653\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 102.800000\n",
            "clicks hr ndcg @ 15 : 0.002213, 0.001162\n",
            "purchase hr and ndcg @15 : 0.009143, 0.005034\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 119.000000\n",
            "clicks hr ndcg @ 20 : 0.002607, 0.001255\n",
            "purchase hr and ndcg @20 : 0.010398, 0.005332\n",
            "#############################################################\n",
            "the loss in 16200th batch is: 7.085410\n",
            "the loss in 16400th batch is: 7.034415\n",
            "the loss in 16600th batch is: 6.741665\n",
            "the loss in 16800th batch is: 7.359010\n",
            "the loss in 17000th batch is: 6.509516\n",
            "the loss in 17200th batch is: 6.457191\n",
            "the loss in 17400th batch is: 6.399929\n",
            "the loss in 17600th batch is: 7.165314\n",
            "the loss in 17800th batch is: 6.799059\n",
            "the loss in 18000th batch is: 6.433833\n",
            "the loss in 18200th batch is: 7.391484\n",
            "the loss in 18400th batch is: 6.493206\n",
            "the loss in 18600th batch is: 6.444749\n",
            "the loss in 18800th batch is: 6.953238\n",
            "the loss in 19000th batch is: 6.800595\n",
            "the loss in 19200th batch is: 6.768317\n",
            "the loss in 19400th batch is: 6.891396\n",
            "the loss in 19600th batch is: 7.072904\n",
            "the loss in 19800th batch is: 6.712345\n",
            "the loss in 20000th batch is: 6.489412\n",
            "#############################################################\n",
            "total clicks: 117015, total purchase:5578\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 65.200000\n",
            "clicks hr ndcg @ 5 : 0.001718, 0.001287\n",
            "purchase hr and ndcg @5 : 0.004482, 0.003045\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 90.600000\n",
            "clicks hr ndcg @ 10 : 0.002418, 0.001517\n",
            "purchase hr and ndcg @10 : 0.006095, 0.003555\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 112.200000\n",
            "clicks hr ndcg @ 15 : 0.002871, 0.001637\n",
            "purchase hr and ndcg @15 : 0.008067, 0.004074\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 138.400000\n",
            "clicks hr ndcg @ 20 : 0.003350, 0.001749\n",
            "purchase hr and ndcg @20 : 0.010757, 0.004711\n",
            "#############################################################\n",
            "the loss in 20200th batch is: 6.340685\n",
            "the loss in 20400th batch is: 6.825309\n",
            "the loss in 20600th batch is: 6.876145\n",
            "the loss in 20800th batch is: 6.894678\n",
            "the loss in 21000th batch is: 6.445916\n",
            "the loss in 21200th batch is: 6.617104\n",
            "the loss in 21400th batch is: 6.171021\n",
            "the loss in 21600th batch is: 6.468662\n",
            "the loss in 21800th batch is: 6.365048\n",
            "the loss in 22000th batch is: 6.500658\n",
            "the loss in 22200th batch is: 6.500253\n",
            "the loss in 22400th batch is: 6.613670\n",
            "the loss in 22600th batch is: 6.290217\n",
            "the loss in 22800th batch is: 6.480409\n",
            "the loss in 23000th batch is: 6.057079\n",
            "the loss in 23200th batch is: 6.451114\n",
            "the loss in 23400th batch is: 6.316641\n",
            "the loss in 23600th batch is: 5.989314\n",
            "the loss in 23800th batch is: 6.141086\n",
            "the loss in 24000th batch is: 6.204701\n",
            "#############################################################\n",
            "total clicks: 117015, total purchase:5578\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 56.200000\n",
            "clicks hr ndcg @ 5 : 0.001120, 0.000802\n",
            "purchase hr and ndcg @5 : 0.005378, 0.003411\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 82.800000\n",
            "clicks hr ndcg @ 10 : 0.001743, 0.001003\n",
            "purchase hr and ndcg @10 : 0.007530, 0.004117\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 102.200000\n",
            "clicks hr ndcg @ 15 : 0.002145, 0.001109\n",
            "purchase hr and ndcg @15 : 0.009322, 0.004580\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 121.800000\n",
            "clicks hr ndcg @ 20 : 0.002555, 0.001207\n",
            "purchase hr and ndcg @20 : 0.011115, 0.005010\n",
            "#############################################################\n",
            "the loss in 24200th batch is: 6.165807\n",
            "the loss in 24400th batch is: 6.590997\n",
            "the loss in 24600th batch is: 5.856431\n",
            "the loss in 24800th batch is: 6.493962\n",
            "the loss in 25000th batch is: 6.031643\n",
            "the loss in 25200th batch is: 6.784346\n",
            "the loss in 25400th batch is: 6.112483\n",
            "the loss in 25600th batch is: 6.019640\n",
            "the loss in 25800th batch is: 6.239745\n",
            "the loss in 26000th batch is: 6.140821\n",
            "the loss in 26200th batch is: 5.926780\n",
            "the loss in 26400th batch is: 6.137142\n",
            "the loss in 26600th batch is: 6.376770\n",
            "the loss in 26800th batch is: 6.286701\n",
            "the loss in 27000th batch is: 6.049386\n",
            "the loss in 27200th batch is: 5.984838\n",
            "the loss in 27400th batch is: 5.707626\n",
            "the loss in 27600th batch is: 6.168487\n",
            "the loss in 27800th batch is: 5.413157\n",
            "the loss in 28000th batch is: 5.490033\n",
            "#############################################################\n",
            "total clicks: 117015, total purchase:5578\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 58.400000\n",
            "clicks hr ndcg @ 5 : 0.001256, 0.000924\n",
            "purchase hr and ndcg @5 : 0.005199, 0.003280\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 91.000000\n",
            "clicks hr ndcg @ 10 : 0.002094, 0.001194\n",
            "purchase hr and ndcg @10 : 0.007530, 0.004051\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 118.000000\n",
            "clicks hr ndcg @ 15 : 0.002863, 0.001399\n",
            "purchase hr and ndcg @15 : 0.009143, 0.004479\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 139.000000\n",
            "clicks hr ndcg @ 20 : 0.003418, 0.001530\n",
            "purchase hr and ndcg @20 : 0.010577, 0.004816\n",
            "#############################################################\n",
            "the loss in 28200th batch is: 6.269019\n",
            "the loss in 28400th batch is: 6.209470\n",
            "the loss in 28600th batch is: 5.949725\n",
            "the loss in 28800th batch is: 6.173137\n",
            "the loss in 29000th batch is: 5.988373\n",
            "the loss in 29200th batch is: 5.598091\n",
            "the loss in 29400th batch is: 5.923704\n",
            "the loss in 29600th batch is: 5.832501\n",
            "the loss in 29800th batch is: 5.907543\n",
            "the loss in 30000th batch is: 5.799490\n",
            "the loss in 30200th batch is: 5.714145\n",
            "the loss in 30400th batch is: 6.339342\n",
            "the loss in 30600th batch is: 6.012550\n",
            "the loss in 30800th batch is: 5.884847\n",
            "the loss in 31000th batch is: 5.944571\n",
            "the loss in 31200th batch is: 5.958263\n",
            "the loss in 31400th batch is: 5.533442\n",
            "the loss in 31600th batch is: 5.600836\n",
            "the loss in 31800th batch is: 6.124598\n",
            "the loss in 32000th batch is: 5.699032\n",
            "#############################################################\n",
            "total clicks: 117015, total purchase:5578\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 60.200000\n",
            "clicks hr ndcg @ 5 : 0.001376, 0.001023\n",
            "purchase hr and ndcg @5 : 0.005020, 0.003653\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 95.600000\n",
            "clicks hr ndcg @ 10 : 0.002119, 0.001262\n",
            "purchase hr and ndcg @10 : 0.008247, 0.004669\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 119.200000\n",
            "clicks hr ndcg @ 15 : 0.002743, 0.001428\n",
            "purchase hr and ndcg @15 : 0.009860, 0.005093\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 136.200000\n",
            "clicks hr ndcg @ 20 : 0.003299, 0.001560\n",
            "purchase hr and ndcg @20 : 0.010577, 0.005263\n",
            "#############################################################\n",
            "the loss in 32200th batch is: 5.976201\n",
            "the loss in 32400th batch is: 5.301974\n",
            "the loss in 32600th batch is: 5.918284\n",
            "the loss in 32800th batch is: 5.904104\n",
            "the loss in 33000th batch is: 5.683490\n",
            "the loss in 33200th batch is: 6.237510\n",
            "the loss in 33400th batch is: 5.688240\n",
            "the loss in 33600th batch is: 5.624249\n",
            "the loss in 33800th batch is: 5.580951\n",
            "the loss in 34000th batch is: 5.883812\n",
            "the loss in 34200th batch is: 5.932922\n",
            "the loss in 34400th batch is: 5.679629\n",
            "the loss in 34600th batch is: 5.646157\n",
            "the loss in 34800th batch is: 6.374924\n",
            "the loss in 35000th batch is: 6.120116\n",
            "the loss in 35200th batch is: 5.689256\n",
            "the loss in 35400th batch is: 5.700341\n",
            "the loss in 35600th batch is: 5.623322\n",
            "the loss in 35800th batch is: 5.695438\n",
            "the loss in 36000th batch is: 5.217648\n",
            "#############################################################\n",
            "total clicks: 117015, total purchase:5578\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 38.800000\n",
            "clicks hr ndcg @ 5 : 0.000889, 0.000593\n",
            "purchase hr and ndcg @5 : 0.003227, 0.002007\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 68.800000\n",
            "clicks hr ndcg @ 10 : 0.001572, 0.000811\n",
            "purchase hr and ndcg @10 : 0.005737, 0.002827\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 98.200000\n",
            "clicks hr ndcg @ 15 : 0.002188, 0.000971\n",
            "purchase hr and ndcg @15 : 0.008426, 0.003529\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 117.600000\n",
            "clicks hr ndcg @ 20 : 0.002632, 0.001076\n",
            "purchase hr and ndcg @20 : 0.010039, 0.003909\n",
            "#############################################################\n",
            "the loss in 36200th batch is: 5.837661\n",
            "the loss in 36400th batch is: 5.645885\n",
            "the loss in 36600th batch is: 5.662809\n",
            "the loss in 36800th batch is: 5.587577\n",
            "the loss in 37000th batch is: 5.583544\n",
            "the loss in 37200th batch is: 5.402349\n",
            "the loss in 37400th batch is: 5.498652\n",
            "the loss in 37600th batch is: 5.658272\n",
            "the loss in 37800th batch is: 5.840966\n",
            "the loss in 38000th batch is: 5.525547\n",
            "the loss in 38200th batch is: 5.778560\n",
            "the loss in 38400th batch is: 5.762376\n"
          ]
        }
      ]
    }
  ]
}