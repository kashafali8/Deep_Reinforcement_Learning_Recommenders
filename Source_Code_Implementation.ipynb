{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kashafali8/Deep_Reinforcement_Learning_Recommenders/blob/main/Source_Code_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HW1C_UDrJ8Kr"
      },
      "source": [
        "# Steps to run the Source code(python scripts) for the final project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brOqImLvKA8g"
      },
      "source": [
        "To run the repositories, you need to upgrade the code to TensorFlow 2. Follow the steps given below to run the python scripts\n",
        "\n",
        "1) Mount you google drive with all the scripts and point to the folder containing the source code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBJK0NgNJqjT",
        "outputId": "b8b1e123-d5f8-4ce0-92fe-bce3d92a476c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/GoogleDrive; to attempt to forcibly remount, call drive.mount(\"/content/GoogleDrive\", force_remount=True).\n",
            "/content/GoogleDrive/My Drive/DUKE/AIPI531_DRL/Project/SA2C_code/Kaggle\n",
            "data\t\t     preprocess_kaggle.py  SA2C.py\t     test.py\n",
            "DQN_NS.py\t     __pycache__\t   SASRecModules.py  utility.py\n",
            "NextItNetModules.py  replay_buffer.py\t   SNQN.py\n",
            "pop.py\t\t     report_SA2C.txt\t   split_data.py\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/GoogleDrive')\n",
        "PROJ_DIR = '/content/GoogleDrive/My Drive/DUKE/AIPI531_DRL/Project/SA2C_code/Kaggle'\n",
        "# change current directory after mounting\n",
        "%cd $PROJ_DIR\n",
        "! ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chqTdLwMOVKY"
      },
      "source": [
        "## 2) Upgrade the source code to TF2 using the following command\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0AC3TlqLdz5",
        "outputId": "04707604-b4d7-4c04-a823-d41763032bde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-04-28 01:55:58.092140: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-28 01:55:59.482286: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO line 74:27: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 77:13: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n",
            "INFO line 79:26: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 80:29: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "WARNING line 84:29: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "INFO line 87:46: Renamed 'tf.nn.dynamic_rnn' to 'tf.compat.v1.nn.dynamic_rnn'\n",
            "INFO line 88:20: Renamed 'tf.contrib.rnn.GRUCell' to 'tf.compat.v1.nn.rnn_cell.GRUCell'\n",
            "INFO line 95:38: Changed tf.to_float call to tf.cast(..., dtype=tf.float32).\n",
            "INFO line 105:25: `name` passed to `name_scope`. Because you may be re-entering an existing scope, it is not safe to convert automatically,  the v2 name_scope does not support re-entering scopes by name.\n",
            "\n",
            "INFO line 105:25: Renamed 'tf.name_scope' to 'tf.compat.v1.name_scope'\n",
            "INFO line 108:40: Renamed 'tf.truncated_normal' to 'tf.random.truncated_normal'\n",
            "INFO line 111:31: Added keywords to args of function 'tf.nn.conv2d'\n",
            "INFO line 111:31: Renamed keyword argument for tf.nn.conv2d from filter to filters\n",
            "INFO line 122:33: Added keywords to args of function 'tf.nn.max_pool'\n",
            "INFO line 122:33: Renamed keyword argument for tf.nn.max_pool from value to input\n",
            "INFO line 122:33: Renamed 'tf.nn.max_pool' to 'tf.nn.max_pool2d'\n",
            "INFO line 135:21: `name` passed to `name_scope`. Because you may be re-entering an existing scope, it is not safe to convert automatically,  the v2 name_scope does not support re-entering scopes by name.\n",
            "\n",
            "INFO line 135:21: Renamed 'tf.name_scope' to 'tf.compat.v1.name_scope'\n",
            "INFO line 137:36: Renamed 'tf.truncated_normal' to 'tf.random.truncated_normal'\n",
            "INFO line 139:27: Added keywords to args of function 'tf.nn.conv2d'\n",
            "INFO line 139:27: Renamed keyword argument for tf.nn.conv2d from filter to filters\n",
            "INFO line 150:21: `name` passed to `name_scope`. Because you may be re-entering an existing scope, it is not safe to convert automatically,  the v2 name_scope does not support re-entering scopes by name.\n",
            "\n",
            "INFO line 150:21: Renamed 'tf.name_scope' to 'tf.compat.v1.name_scope'\n",
            "INFO line 151:41: Renamed 'tf.layers.dropout' to 'tf.compat.v1.layers.dropout'\n",
            "INFO line 156:38: Changed tf.to_float call to tf.cast(..., dtype=tf.float32).\n",
            "WARNING line 165:36: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "WARNING line 180:26: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "INFO line 185:38: Changed tf.to_float call to tf.cast(..., dtype=tf.float32).\n",
            "INFO line 187:27: Renamed 'tf.layers.dropout' to 'tf.compat.v1.layers.dropout'\n",
            "INFO line 195:25: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n",
            "INFO line 222:27: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 224:34: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 226:29: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 227:37: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 229:26: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 230:28: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 232:36: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 233:44: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 239:33: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 275:24: Renamed 'tf.train.AdamOptimizer' to 'tf.compat.v1.train.AdamOptimizer'\n",
            "INFO line 278:24: Renamed 'tf.train.AdamOptimizer' to 'tf.compat.v1.train.AdamOptimizer'\n",
            "INFO line 284:17: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n",
            "INFO line 285:47: Renamed 'tf.random_normal' to 'tf.random.normal'\n",
            "INFO line 287:45: Renamed 'tf.random_normal' to 'tf.random.normal'\n",
            "INFO line 385:4: Renamed 'tf.reset_default_graph' to 'tf.compat.v1.reset_default_graph'\n",
            "INFO line 401:9: Renamed 'tf.Session' to 'tf.compat.v1.Session'\n",
            "INFO line 403:17: Renamed 'tf.global_variables_initializer' to 'tf.compat.v1.global_variables_initializer'\n",
            "TensorFlow 2.0 Upgrade Script\n",
            "-----------------------------\n",
            "Converted 1 files\n",
            "Detected 3 issues that require attention\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "File: /content/GoogleDrive/My Drive/DUKE/AIPI531_DRL/Project/SA2C_code/Kaggle/SA2C.py\n",
            "--------------------------------------------------------------------------------\n",
            "/content/GoogleDrive/My Drive/DUKE/AIPI531_DRL/Project/SA2C_code/Kaggle/SA2C.py:84:29: WARNING: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "/content/GoogleDrive/My Drive/DUKE/AIPI531_DRL/Project/SA2C_code/Kaggle/SA2C.py:165:36: WARNING: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "/content/GoogleDrive/My Drive/DUKE/AIPI531_DRL/Project/SA2C_code/Kaggle/SA2C.py:180:26: WARNING: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "\n",
            "\n",
            "Make sure to read the detailed log 'report_SA2C.txt'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!tf_upgrade_v2 \\\n",
        "  --infile '/content/GoogleDrive/My Drive/DUKE/AIPI531_DRL/Project/SA2C_code/Kaggle/SA2C.py' \\\n",
        "  --outfile '/content/GoogleDrive/My Drive/DUKE/AIPI531_DRL/Project/SA2C_code/Kaggle/SA2C_new.py' \\\n",
        "  --reportfile report_SA2C.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpDKJkdhOUHH",
        "outputId": "991632ac-31ac-4c29-aca2-06eb532d04df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Collecting trfl\n",
            "  Downloading trfl-1.2.0-py3-none-any.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from trfl) (1.4.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from trfl) (1.14.1)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from trfl) (0.1.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from trfl) (1.16.0)\n",
            "Installing collected packages: trfl\n",
            "Successfully installed trfl-1.2.0\n"
          ]
        }
      ],
      "source": [
        "! pip install pandas trfl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u29uv_5oS7H5"
      },
      "source": [
        "## 3) Then just provide appropriate arguments and select the model you want to train on and execute "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShqGvAmcSJWb",
        "outputId": "35de2cb5-f8fa-40de-fe8a-81c9ba5705ba"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-04-28 01:56:18.531282: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-28 01:56:19.529487: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/content/GoogleDrive/MyDrive/DUKE/AIPI531_DRL/Project/SA2C_code/Kaggle/SA2C_new.py:88: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n",
            "WARNING:tensorflow:From /content/GoogleDrive/MyDrive/DUKE/AIPI531_DRL/Project/SA2C_code/Kaggle/SA2C_new.py:87: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/layers/rnn/legacy_cells.py:584: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/layers/rnn/legacy_cells.py:598: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "/content/GoogleDrive/MyDrive/DUKE/AIPI531_DRL/Project/SA2C_code/Kaggle/SA2C_new.py:215: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n",
            "/content/GoogleDrive/MyDrive/DUKE/AIPI531_DRL/Project/SA2C_code/Kaggle/SA2C_new.py:218: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output2= tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n",
            "2023-04-28 01:56:35.185932: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
            "the loss in 200th batch is: 10.719890\n",
            "the loss in 400th batch is: 10.685548\n",
            "the loss in 600th batch is: 10.636658\n",
            "the loss in 800th batch is: 10.433790\n",
            "the loss in 1000th batch is: 10.241999\n",
            "the loss in 1200th batch is: 10.090664\n",
            "the loss in 1400th batch is: 10.077801\n",
            "the loss in 1600th batch is: 9.672892\n"
          ]
        }
      ],
      "source": [
        "! python SA2C_new.py --model=GRU --epoch=1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# downloading the \"transactions_train.csv\" datafile from the H&M Dataset\n",
        "!wget https://aipi590.s3.amazonaws.com/transactions_train.csv -P \"/content/GoogleDrive/My Drive/DUKE/AIPI531_DRL/Project/Data\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REenvPNscYPU",
        "outputId": "c98b4ed2-bf65-434f-ec2a-ab971e3dc57b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-28 06:00:32--  https://aipi590.s3.amazonaws.com/transactions_train.csv\n",
            "Resolving aipi590.s3.amazonaws.com (aipi590.s3.amazonaws.com)... 52.216.109.171, 52.217.131.177, 52.217.206.145, ...\n",
            "Connecting to aipi590.s3.amazonaws.com (aipi590.s3.amazonaws.com)|52.216.109.171|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3488002253 (3.2G) [text/csv]\n",
            "Saving to: ‘/content/GoogleDrive/My Drive/DUKE/AIPI531_DRL/Project/Data/transactions_train.csv’\n",
            "\n",
            "transactions_train. 100%[===================>]   3.25G  55.8MB/s    in 63s     \n",
            "\n",
            "2023-04-28 06:01:36 (52.5 MB/s) - ‘/content/GoogleDrive/My Drive/DUKE/AIPI531_DRL/Project/Data/transactions_train.csv’ saved [3488002253/3488002253]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ik62MKaheqr4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIGF5is0PsmkFLINRghK29",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}