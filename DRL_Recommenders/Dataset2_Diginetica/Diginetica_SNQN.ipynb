{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnsFQ76ZxT0V2RDzSE6h0V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kashafali8/Deep_Reinforcement_Learning_Recommenders/blob/main/DRL_Recommenders/Dataset2_Diginetica/Diginetica_SNQN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 1: Load Required Packages"
      ],
      "metadata": {
        "id": "gvWgO9m9WwQE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WX21I_X_jp8-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "! pip install pandas trfl\n"
      ],
      "metadata": {
        "id": "Yzjklqa8W7CK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install tensorflow==2.11.0"
      ],
      "metadata": {
        "id": "TYfNHJS0XhYL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install tensorflow-gpu==2.11.0\n",
        "# !pip install numpy==1.19.5"
      ],
      "metadata": {
        "id": "eshLNsgp_K0A"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Mount Google Drive and Manage Cloned Github Repository"
      ],
      "metadata": {
        "id": "sbMVbj8pYIoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/GoogleDrive')\n",
        "PROJ_DIR = '/content/GoogleDrive/My Drive/DUKE/AIPI531_DRL/Project'\n",
        "# change current directory after mounting\n",
        "%cd $PROJ_DIR\n",
        "! ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3OPLMWlkBRk",
        "outputId": "8e7eeab1-22da-41e8-ee34-bfa5bc76ae40"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/GoogleDrive\n",
            "/content/GoogleDrive/My Drive/DUKE/AIPI531_DRL/Project\n",
            " Data\t\t\t\t\t    report_SNQN.txt\n",
            " Deep_Reinforcement_Learning_Recommenders   SA2C_code\n",
            " Diginetica_Preprocess.ipynb\t\t    SA2C_code.zip\n",
            "'Diginetica_SNQN (1).ipynb'\t\t   'Source Code Implementation.ipynb'\n",
            " Diginetica_SNQN.ipynb\t\t\t    Untitled0.ipynb\n",
            " pop_dict.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! apt-get install git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OskxNDEkTtM",
        "outputId": "395a3a07-867b-4e3b-cae9-475724354333"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "git is already the newest version (1:2.25.1-1ubuntu3.11).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/kashafali8/Deep_Reinforcement_Learning_Recommenders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QikIEW2ZkoIJ",
        "outputId": "a04ac46c-dc85-41d9-edfc-159dc6014e32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Deep_Reinforcement_Learning_Recommenders'...\n",
            "remote: Enumerating objects: 112, done.\u001b[K\n",
            "remote: Counting objects: 100% (112/112), done.\u001b[K\n",
            "remote: Compressing objects: 100% (91/91), done.\u001b[K\n",
            "remote: Total 112 (delta 39), reused 49 (delta 13), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (112/112), 43.46 KiB | 1.17 MiB/s, done.\n",
            "Resolving deltas: 100% (39/39), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%cd Deep_Reinforcement_Learning_Recommenders"
      ],
      "metadata": {
        "id": "IMtLLtgNBxq2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjVzjEzjnZBq",
        "outputId": "624b419e-046e-4342-ee2c-dbac51718a07"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mDRL_Recommenders\u001b[0m/  LICENSE  README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!git pull"
      ],
      "metadata": {
        "id": "8tbm8W6cnasM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etZ9ckERnd-B",
        "outputId": "fb81da35-fa47-4556-bc08-a37e745423b3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/GoogleDrive/My Drive/DUKE/AIPI531_DRL/Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Run Preprocessing Files (Replay_Buffer and Pop) on cleaned dataset"
      ],
      "metadata": {
        "id": "k39_I2DPWvTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset2_Diginetica/src/replay_buffer_v1.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_mrfuEol0HR",
        "outputId": "666b75b0-e0a2-44af-f958-745338585bb6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-04 17:41:15.467225: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-04 17:41:16.470131: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-05-04 17:41:16.470297: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-05-04 17:41:16.470316: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset2_Diginetica/src/pop_v1.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NFKYud4m38e",
        "outputId": "1aba1db2-c25a-41ae-b4ec-c1f91128b71c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "1.0\n",
            "2.0\n",
            "3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: SNQN Model with SASRec (without item features)"
      ],
      "metadata": {
        "id": "6eSUuZiuYw0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "tac = time.time()\n",
        "\n",
        "!python Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset2_Diginetica/src/SNQN_V.py --model=SASRec --epoch=1\n",
        "\n",
        "tic = time.time()\n",
        "print(f\"Time to run 15 epochs: {np.round((tic-tac)/60,2)} minutes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4I4drH7Ij21",
        "outputId": "5b149b0f-9cfc-4f21-80ae-45ce6f05dbee"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-04 18:59:38.649063: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-04 18:59:39.740556: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-05-04 18:59:39.740668: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-05-04 18:59:39.740687: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "Built with cuda: <function is_built_with_cuda at 0x7f76da44d090>\n",
            "2023-05-04 18:59:42.792372: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "/device:GPU:0\n",
            "#############################################################\n",
            "total clicks: 36997, total purchase:958\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 1.600000\n",
            "clicks hr ndcg @ 5 : 0.000216, 0.000101\n",
            "purchase hr and ndcg @5 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 2.400000\n",
            "clicks hr ndcg @ 10 : 0.000324, 0.000135\n",
            "purchase hr and ndcg @10 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 2.600000\n",
            "clicks hr ndcg @ 15 : 0.000351, 0.000143\n",
            "purchase hr and ndcg @15 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 4.600000\n",
            "clicks hr ndcg @ 20 : 0.000622, 0.000206\n",
            "purchase hr and ndcg @20 : 0.000000, 0.000000\n",
            "#############################################################\n",
            "the loss in 200th batch is: 10.890174\n",
            "the loss in 400th batch is: 10.603991\n",
            "the loss in 600th batch is: 10.343645\n",
            "the loss in 800th batch is: 10.274446\n",
            "the loss in 1000th batch is: 10.152638\n",
            "Time to run 15 epochs: 6.98 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "tac = time.time()\n",
        "\n",
        "!python Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset2_Diginetica/src/SNQN_V.py --model=SASRec --epoch=15\n",
        "\n",
        "tic = time.time()\n",
        "print(f\"Time to run 15 epochs: {np.round((tic-tac)/60,2)} minutes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8Ps7o7O2qOQ",
        "outputId": "3f543d8d-654e-41a9-a40e-4bf33006ac23"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-04 17:42:38.040752: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-04 17:42:39.538990: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-05-04 17:42:39.539394: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-05-04 17:42:39.539427: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "Built with cuda: <function is_built_with_cuda at 0x7fdcaf091090>\n",
            "2023-05-04 17:42:45.359937: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "/device:GPU:0\n",
            "2023-05-04 17:42:50.118507: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 18489088 exceeds 10% of free system memory.\n",
            "2023-05-04 17:42:50.158601: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 18488832 exceeds 10% of free system memory.\n",
            "2023-05-04 17:42:50.196284: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 18488832 exceeds 10% of free system memory.\n",
            "2023-05-04 17:42:50.223793: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 18489088 exceeds 10% of free system memory.\n",
            "2023-05-04 17:42:50.256314: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 18488832 exceeds 10% of free system memory.\n",
            "#############################################################\n",
            "total clicks: 36997, total purchase:958\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 1.400000\n",
            "clicks hr ndcg @ 5 : 0.000189, 0.000091\n",
            "purchase hr and ndcg @5 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 2.000000\n",
            "clicks hr ndcg @ 10 : 0.000270, 0.000117\n",
            "purchase hr and ndcg @10 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 3.000000\n",
            "clicks hr ndcg @ 15 : 0.000405, 0.000152\n",
            "purchase hr and ndcg @15 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 5.600000\n",
            "clicks hr ndcg @ 20 : 0.000622, 0.000203\n",
            "purchase hr and ndcg @20 : 0.001044, 0.000238\n",
            "#############################################################\n",
            "the loss in 200th batch is: 11.049854\n",
            "the loss in 400th batch is: 10.626395\n",
            "the loss in 600th batch is: 10.422226\n",
            "the loss in 800th batch is: 10.380806\n",
            "the loss in 1000th batch is: 10.149979\n",
            "the loss in 1200th batch is: 9.964306\n",
            "the loss in 1400th batch is: 9.927853\n",
            "the loss in 1600th batch is: 10.082127\n",
            "the loss in 1800th batch is: 9.677661\n",
            "the loss in 2000th batch is: 9.645423\n",
            "the loss in 2200th batch is: 9.626716\n",
            "the loss in 2400th batch is: 9.531447\n",
            "the loss in 2600th batch is: 9.556878\n",
            "the loss in 2800th batch is: 9.000213\n",
            "the loss in 3000th batch is: 9.038143\n",
            "the loss in 3200th batch is: 8.783489\n",
            "the loss in 3400th batch is: 8.772297\n",
            "the loss in 3600th batch is: 8.350277\n",
            "the loss in 3800th batch is: 8.434185\n",
            "the loss in 4000th batch is: 8.205712\n",
            "#############################################################\n",
            "total clicks: 36997, total purchase:958\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 1314.200000\n",
            "clicks hr ndcg @ 5 : 0.151796, 0.112361\n",
            "purchase hr and ndcg @5 : 0.199374, 0.158908\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 1612.800000\n",
            "clicks hr ndcg @ 10 : 0.188907, 0.124380\n",
            "purchase hr and ndcg @10 : 0.224426, 0.166943\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 1785.200000\n",
            "clicks hr ndcg @ 15 : 0.211125, 0.130253\n",
            "purchase hr and ndcg @15 : 0.232777, 0.169134\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 1911.400000\n",
            "clicks hr ndcg @ 20 : 0.227235, 0.134055\n",
            "purchase hr and ndcg @20 : 0.240084, 0.170864\n",
            "#############################################################\n",
            "the loss in 4200th batch is: 8.058239\n",
            "the loss in 4400th batch is: 7.901395\n",
            "the loss in 4600th batch is: 7.736947\n",
            "the loss in 4800th batch is: 7.715259\n",
            "the loss in 5000th batch is: 7.883286\n",
            "the loss in 5200th batch is: 7.639605\n",
            "the loss in 5400th batch is: 7.796900\n",
            "the loss in 5600th batch is: 7.230822\n",
            "the loss in 5800th batch is: 7.624548\n",
            "the loss in 6000th batch is: 7.196962\n",
            "the loss in 6200th batch is: 7.018442\n",
            "the loss in 6400th batch is: 7.137778\n",
            "the loss in 6600th batch is: 7.079118\n",
            "the loss in 6800th batch is: 6.479236\n",
            "the loss in 7000th batch is: 6.967687\n",
            "the loss in 7200th batch is: 6.686095\n",
            "the loss in 7400th batch is: 6.775530\n",
            "the loss in 7600th batch is: 6.496237\n",
            "the loss in 7800th batch is: 6.598066\n",
            "the loss in 8000th batch is: 6.788568\n",
            "#############################################################\n",
            "total clicks: 36997, total purchase:958\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 1603.200000\n",
            "clicks hr ndcg @ 5 : 0.188691, 0.134394\n",
            "purchase hr and ndcg @5 : 0.216075, 0.166141\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 1997.400000\n",
            "clicks hr ndcg @ 10 : 0.236830, 0.149968\n",
            "purchase hr and ndcg @10 : 0.255741, 0.179104\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 2208.400000\n",
            "clicks hr ndcg @ 15 : 0.263859, 0.157127\n",
            "purchase hr and ndcg @15 : 0.267223, 0.182120\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 2352.600000\n",
            "clicks hr ndcg @ 20 : 0.281996, 0.161416\n",
            "purchase hr and ndcg @20 : 0.277662, 0.184577\n",
            "#############################################################\n",
            "the loss in 8200th batch is: 6.464059\n",
            "the loss in 8400th batch is: 6.288327\n",
            "the loss in 8600th batch is: 6.536891\n",
            "the loss in 8800th batch is: 6.334629\n",
            "the loss in 9000th batch is: 6.549332\n",
            "the loss in 9200th batch is: 6.187091\n",
            "the loss in 9400th batch is: 6.282207\n",
            "the loss in 9600th batch is: 6.584530\n",
            "the loss in 9800th batch is: 5.988889\n",
            "the loss in 10000th batch is: 6.122913\n",
            "the loss in 10200th batch is: 6.176895\n",
            "the loss in 10400th batch is: 6.432378\n",
            "the loss in 10600th batch is: 6.297652\n",
            "the loss in 10800th batch is: 6.011554\n",
            "the loss in 11000th batch is: 5.922002\n",
            "the loss in 11200th batch is: 5.913649\n",
            "the loss in 11400th batch is: 5.640259\n",
            "the loss in 11600th batch is: 5.979708\n",
            "the loss in 11800th batch is: 5.633428\n",
            "the loss in 12000th batch is: 5.111737\n",
            "#############################################################\n",
            "total clicks: 36997, total purchase:958\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 1641.600000\n",
            "clicks hr ndcg @ 5 : 0.192935, 0.136791\n",
            "purchase hr and ndcg @5 : 0.223382, 0.163898\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 2057.200000\n",
            "clicks hr ndcg @ 10 : 0.245723, 0.153893\n",
            "purchase hr and ndcg @10 : 0.249478, 0.172551\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 2277.400000\n",
            "clicks hr ndcg @ 15 : 0.272779, 0.161056\n",
            "purchase hr and ndcg @15 : 0.270355, 0.178161\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 2431.600000\n",
            "clicks hr ndcg @ 20 : 0.292537, 0.165721\n",
            "purchase hr and ndcg @20 : 0.278706, 0.180125\n",
            "#############################################################\n",
            "the loss in 12200th batch is: 5.546725\n",
            "the loss in 12400th batch is: 5.650338\n",
            "the loss in 12600th batch is: 5.725282\n",
            "the loss in 12800th batch is: 5.623240\n",
            "the loss in 13000th batch is: 5.405121\n",
            "the loss in 13200th batch is: 5.283273\n",
            "the loss in 13400th batch is: 5.520201\n",
            "the loss in 13600th batch is: 5.212669\n",
            "the loss in 13800th batch is: 5.368213\n",
            "the loss in 14000th batch is: 5.384651\n",
            "the loss in 14200th batch is: 4.976633\n",
            "the loss in 14400th batch is: 5.559904\n",
            "the loss in 14600th batch is: 5.028589\n",
            "the loss in 14800th batch is: 5.360095\n",
            "the loss in 15000th batch is: 5.325182\n",
            "the loss in 15200th batch is: 5.301110\n",
            "the loss in 15400th batch is: 5.348457\n",
            "the loss in 15600th batch is: 5.567407\n",
            "the loss in 15800th batch is: 5.010094\n",
            "the loss in 16000th batch is: 5.372774\n",
            "#############################################################\n",
            "total clicks: 36997, total purchase:958\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 1609.800000\n",
            "clicks hr ndcg @ 5 : 0.190259, 0.133517\n",
            "purchase hr and ndcg @5 : 0.210856, 0.150178\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 2042.800000\n",
            "clicks hr ndcg @ 10 : 0.243912, 0.150934\n",
            "purchase hr and ndcg @10 : 0.248434, 0.162224\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 2290.600000\n",
            "clicks hr ndcg @ 15 : 0.274022, 0.158898\n",
            "purchase hr and ndcg @15 : 0.274530, 0.169245\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 2451.800000\n",
            "clicks hr ndcg @ 20 : 0.294727, 0.163795\n",
            "purchase hr and ndcg @20 : 0.282881, 0.171205\n",
            "#############################################################\n",
            "the loss in 16200th batch is: 5.021155\n",
            "the loss in 16400th batch is: 5.233848\n",
            "the loss in 16600th batch is: 4.741902\n",
            "the loss in 16800th batch is: 4.836369\n",
            "the loss in 17000th batch is: 4.936946\n",
            "the loss in 17200th batch is: 5.015492\n",
            "the loss in 17400th batch is: 5.180501\n",
            "the loss in 17600th batch is: 5.182488\n",
            "Time to run 15 epochs: 68.28 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: SNQN Model with SASRec (with item features)"
      ],
      "metadata": {
        "id": "y1kDIr1gZDRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "tac = time.time()\n",
        "\n",
        "!python Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset2_Diginetica/src/SNQN_P.py --model=SASRec --epoch=1\n",
        "\n",
        "tic = time.time()\n",
        "print(f\"Time to run 15 epochs: {np.round((tic-tac)/60,2)} minutes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFUk8l-SvYy7",
        "outputId": "ba636036-db59-4f1d-d1e4-3c8f1d4e8257"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-03 17:10:18.583302: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-03 17:10:19.945234: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-05-03 17:10:19.945351: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-05-03 17:10:19.945385: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "Built with cuda: <function is_built_with_cuda at 0x7f115d671090>\n",
            "2023-05-03 17:10:23.513279: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "/device:GPU:0\n",
            "OUTPUT 2 SHAPE:  (None, 72222)\n",
            "w_f SHAPE:  (72222, 64)\n",
            "phi 2 SHAPE:  (None, 72222)\n",
            "final score SHAPE:  (None, 72222)\n",
            "ce_loss SHAPE:  (None,)\n",
            "OUTPUT 2 SHAPE:  (None, 72222)\n",
            "w_f SHAPE:  (72222, 64)\n",
            "phi 2 SHAPE:  (None, 72222)\n",
            "final score SHAPE:  (None, 72222)\n",
            "ce_loss SHAPE:  (None,)\n",
            "#############################################################\n",
            "total clicks: 36997, total purchase:958\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 1.400000\n",
            "clicks hr ndcg @ 5 : 0.000189, 0.000091\n",
            "purchase hr and ndcg @5 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 1.800000\n",
            "clicks hr ndcg @ 10 : 0.000243, 0.000107\n",
            "purchase hr and ndcg @10 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 2.200000\n",
            "clicks hr ndcg @ 15 : 0.000297, 0.000122\n",
            "purchase hr and ndcg @15 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 3.800000\n",
            "clicks hr ndcg @ 20 : 0.000514, 0.000173\n",
            "purchase hr and ndcg @20 : 0.000000, 0.000000\n",
            "#############################################################\n",
            "the loss in 200th batch is: 11.063989\n",
            "the loss in 400th batch is: 10.617736\n",
            "the loss in 600th batch is: 10.473333\n",
            "the loss in 800th batch is: 10.543546\n",
            "the loss in 1000th batch is: 10.330119\n",
            "Time to run 15 epochs: 9.74 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "tac = time.time()\n",
        "\n",
        "!python Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset2_Diginetica/src/SNQN_P.py --model=SASRec --epoch=15\n",
        "\n",
        "tic = time.time()\n",
        "print(f\"Time to run 15 epochs: {np.round((tic-tac)/60,2)} minutes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIiFP92CoU2u",
        "outputId": "a60dae3d-19a3-47ed-c7d3-93beb2ae3dbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-03 17:20:41.555610: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-03 17:20:43.686456: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-05-03 17:20:43.686628: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-05-03 17:20:43.686650: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "Built with cuda: <function is_built_with_cuda at 0x7facbb021090>\n",
            "2023-05-03 17:20:48.046532: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "/device:GPU:0\n",
            "OUTPUT 2 SHAPE:  (None, 72222)\n",
            "w_f SHAPE:  (72222, 64)\n",
            "phi 2 SHAPE:  (None, 72222)\n",
            "final score SHAPE:  (None, 72222)\n",
            "ce_loss SHAPE:  (None,)\n",
            "OUTPUT 2 SHAPE:  (None, 72222)\n",
            "w_f SHAPE:  (72222, 64)\n",
            "phi 2 SHAPE:  (None, 72222)\n",
            "final score SHAPE:  (None, 72222)\n",
            "ce_loss SHAPE:  (None,)\n",
            "#############################################################\n",
            "total clicks: 36997, total purchase:958\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 1.600000\n",
            "clicks hr ndcg @ 5 : 0.000216, 0.000101\n",
            "purchase hr and ndcg @5 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 2.000000\n",
            "clicks hr ndcg @ 10 : 0.000270, 0.000118\n",
            "purchase hr and ndcg @10 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 2.800000\n",
            "clicks hr ndcg @ 15 : 0.000378, 0.000146\n",
            "purchase hr and ndcg @15 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 4.600000\n",
            "clicks hr ndcg @ 20 : 0.000622, 0.000204\n",
            "purchase hr and ndcg @20 : 0.000000, 0.000000\n",
            "#############################################################\n",
            "the loss in 200th batch is: 11.078665\n",
            "the loss in 400th batch is: 10.468855\n",
            "the loss in 600th batch is: 10.550458\n",
            "the loss in 800th batch is: 10.364820\n",
            "the loss in 1000th batch is: 10.434830\n",
            "the loss in 1200th batch is: 10.149935\n",
            "the loss in 1400th batch is: 10.196102\n",
            "the loss in 1600th batch is: 10.040846\n",
            "the loss in 1800th batch is: 9.870436\n",
            "the loss in 2000th batch is: 9.778118\n",
            "the loss in 2200th batch is: 9.804740\n",
            "the loss in 2400th batch is: 9.807614\n",
            "the loss in 2600th batch is: 9.598760\n",
            "the loss in 2800th batch is: 9.569325\n",
            "the loss in 3000th batch is: 9.584492\n",
            "the loss in 3200th batch is: 9.362872\n",
            "the loss in 3400th batch is: 9.445540\n",
            "the loss in 3600th batch is: 8.824454\n",
            "the loss in 3800th batch is: 8.912210\n",
            "the loss in 4000th batch is: 9.074606\n",
            "#############################################################\n",
            "total clicks: 36997, total purchase:958\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 751.800000\n",
            "clicks hr ndcg @ 5 : 0.086196, 0.060503\n",
            "purchase hr and ndcg @5 : 0.118998, 0.084209\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 1052.400000\n",
            "clicks hr ndcg @ 10 : 0.122632, 0.072282\n",
            "purchase hr and ndcg @10 : 0.151357, 0.094784\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 1222.200000\n",
            "clicks hr ndcg @ 15 : 0.144093, 0.077953\n",
            "purchase hr and ndcg @15 : 0.162839, 0.097844\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 1335.800000\n",
            "clicks hr ndcg @ 20 : 0.158634, 0.081388\n",
            "purchase hr and ndcg @20 : 0.169102, 0.099334\n",
            "#############################################################\n",
            "the loss in 4200th batch is: 8.635911\n",
            "the loss in 4400th batch is: 8.530931\n",
            "the loss in 4600th batch is: 8.621290\n",
            "the loss in 4800th batch is: 8.409353\n",
            "the loss in 5000th batch is: 8.300646\n",
            "the loss in 5200th batch is: 8.261346\n",
            "the loss in 5400th batch is: 8.121585\n",
            "the loss in 5600th batch is: 8.075040\n",
            "the loss in 5800th batch is: 8.180552\n",
            "the loss in 6000th batch is: 8.392408\n",
            "the loss in 6200th batch is: 7.596923\n",
            "the loss in 6400th batch is: 7.762790\n",
            "the loss in 6600th batch is: 7.363431\n",
            "the loss in 6800th batch is: 7.673285\n",
            "the loss in 7000th batch is: 7.521556\n",
            "the loss in 7200th batch is: 7.465395\n",
            "the loss in 7400th batch is: 7.331930\n",
            "the loss in 7600th batch is: 7.040812\n",
            "the loss in 7800th batch is: 7.116755\n",
            "the loss in 8000th batch is: 7.132916\n",
            "#############################################################\n",
            "total clicks: 36997, total purchase:958\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 932.400000\n",
            "clicks hr ndcg @ 5 : 0.110198, 0.078260\n",
            "purchase hr and ndcg @5 : 0.122129, 0.084197\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 1304.400000\n",
            "clicks hr ndcg @ 10 : 0.154661, 0.092621\n",
            "purchase hr and ndcg @10 : 0.167015, 0.098873\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 1540.200000\n",
            "clicks hr ndcg @ 15 : 0.183420, 0.100227\n",
            "purchase hr and ndcg @15 : 0.191023, 0.105255\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 1731.200000\n",
            "clicks hr ndcg @ 20 : 0.206260, 0.105620\n",
            "purchase hr and ndcg @20 : 0.213987, 0.110704\n",
            "#############################################################\n",
            "the loss in 8200th batch is: 7.216875\n",
            "the loss in 8400th batch is: 6.998063\n",
            "the loss in 8600th batch is: 6.974887\n",
            "the loss in 8800th batch is: 6.870090\n",
            "the loss in 9000th batch is: 7.155300\n",
            "the loss in 9200th batch is: 7.051579\n",
            "the loss in 9400th batch is: 6.990838\n",
            "the loss in 9600th batch is: 6.847420\n",
            "the loss in 9800th batch is: 6.417974\n",
            "the loss in 10000th batch is: 6.645166\n",
            "the loss in 10200th batch is: 6.549894\n",
            "the loss in 10400th batch is: 6.877969\n",
            "the loss in 10600th batch is: 6.471658\n",
            "the loss in 10800th batch is: 6.477733\n",
            "the loss in 11000th batch is: 6.046476\n",
            "the loss in 11200th batch is: 6.731045\n",
            "the loss in 11400th batch is: 6.822513\n",
            "the loss in 11600th batch is: 6.227319\n",
            "the loss in 11800th batch is: 6.448014\n",
            "the loss in 12000th batch is: 5.844338\n",
            "#############################################################\n",
            "total clicks: 36997, total purchase:958\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 943.400000\n",
            "clicks hr ndcg @ 5 : 0.113036, 0.081236\n",
            "purchase hr and ndcg @5 : 0.111691, 0.078424\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 1339.000000\n",
            "clicks hr ndcg @ 10 : 0.160148, 0.096400\n",
            "purchase hr and ndcg @10 : 0.160752, 0.094519\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 1600.200000\n",
            "clicks hr ndcg @ 15 : 0.191934, 0.104792\n",
            "purchase hr and ndcg @15 : 0.187891, 0.101722\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 1799.400000\n",
            "clicks hr ndcg @ 20 : 0.215747, 0.110410\n",
            "purchase hr and ndcg @20 : 0.211900, 0.107409\n",
            "#############################################################\n",
            "the loss in 12200th batch is: 6.244498\n",
            "the loss in 12400th batch is: 5.913230\n",
            "the loss in 12600th batch is: 6.299222\n",
            "the loss in 12800th batch is: 6.282725\n",
            "the loss in 13000th batch is: 6.206264\n",
            "the loss in 13200th batch is: 6.112100\n",
            "the loss in 13400th batch is: 5.839002\n",
            "the loss in 13600th batch is: 6.064917\n",
            "the loss in 13800th batch is: 5.874168\n",
            "the loss in 14000th batch is: 5.626927\n",
            "the loss in 14200th batch is: 5.787145\n",
            "the loss in 14400th batch is: 6.144256\n",
            "the loss in 14600th batch is: 6.132226\n",
            "the loss in 14800th batch is: 6.163404\n",
            "the loss in 15000th batch is: 6.075842\n",
            "the loss in 15200th batch is: 6.069593\n",
            "the loss in 15400th batch is: 5.772510\n",
            "the loss in 15600th batch is: 6.064425\n",
            "the loss in 15800th batch is: 5.831459\n",
            "the loss in 16000th batch is: 6.066615\n",
            "#############################################################\n",
            "total clicks: 36997, total purchase:958\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 951.800000\n",
            "clicks hr ndcg @ 5 : 0.113090, 0.081594\n",
            "purchase hr and ndcg @5 : 0.120042, 0.081328\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 1338.400000\n",
            "clicks hr ndcg @ 10 : 0.160067, 0.096746\n",
            "purchase hr and ndcg @10 : 0.160752, 0.094191\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 1605.200000\n",
            "clicks hr ndcg @ 15 : 0.192205, 0.105245\n",
            "purchase hr and ndcg @15 : 0.191023, 0.102181\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 1806.400000\n",
            "clicks hr ndcg @ 20 : 0.217099, 0.111118\n",
            "purchase hr and ndcg @20 : 0.208768, 0.106387\n",
            "#############################################################\n",
            "the loss in 16200th batch is: 5.677097\n",
            "the loss in 16400th batch is: 5.777821\n",
            "the loss in 16600th batch is: 5.675600\n",
            "the loss in 16800th batch is: 5.836801\n",
            "the loss in 17000th batch is: 5.644711\n",
            "the loss in 17200th batch is: 5.601398\n",
            "the loss in 17400th batch is: 5.792737\n",
            "the loss in 17600th batch is: 5.918202\n",
            "Time to run 15 epochs: 88.12 minutes\n"
          ]
        }
      ]
    }
  ]
}