{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOaC1zq8jYuWvVcz/TPUM37",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kashafali8/Deep_Reinforcement_Learning_Recommenders/blob/main/DRL_Recommenders/Dataset2_Diginetica/Diginetica_SNQN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 1: Load Required Packages"
      ],
      "metadata": {
        "id": "gvWgO9m9WwQE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WX21I_X_jp8-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "! pip install pandas trfl\n"
      ],
      "metadata": {
        "id": "Yzjklqa8W7CK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install tensorflow==2.11.0"
      ],
      "metadata": {
        "id": "TYfNHJS0XhYL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install tensorflow-gpu==2.11.0\n",
        "# !pip install numpy==1.19.5"
      ],
      "metadata": {
        "id": "eshLNsgp_K0A"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Mount Google Drive and Manage Cloned Github Repository"
      ],
      "metadata": {
        "id": "sbMVbj8pYIoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/GoogleDrive')\n",
        "PROJ_DIR = '/content/GoogleDrive/My Drive/DUKE/AIPI531_DRL/Project'\n",
        "# change current directory after mounting\n",
        "%cd $PROJ_DIR\n",
        "! ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3OPLMWlkBRk",
        "outputId": "f6724fb9-81b4-41d0-8d4c-e379b811a747"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/GoogleDrive\n",
            "/content/GoogleDrive/My Drive/DUKE/AIPI531_DRL/Project\n",
            " Data\t\t\t\t\t    report_SNQN.txt\n",
            " Deep_Reinforcement_Learning_Recommenders   SA2C_code\n",
            " Diginetica_Preprocess.ipynb\t\t    SA2C_code.zip\n",
            "'Diginetica_SNQN (1).ipynb'\t\t   'Source Code Implementation.ipynb'\n",
            " Diginetica_SNQN.ipynb\t\t\t    Untitled0.ipynb\n",
            " pop_dict.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! apt-get install git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OskxNDEkTtM",
        "outputId": "109add50-90f5-4c28-c234-3fa070edff4c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "git is already the newest version (1:2.25.1-1ubuntu3.11).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/kashafali8/Deep_Reinforcement_Learning_Recommenders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QikIEW2ZkoIJ",
        "outputId": "a04ac46c-dc85-41d9-edfc-159dc6014e32"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Deep_Reinforcement_Learning_Recommenders'...\n",
            "remote: Enumerating objects: 112, done.\u001b[K\n",
            "remote: Counting objects: 100% (112/112), done.\u001b[K\n",
            "remote: Compressing objects: 100% (91/91), done.\u001b[K\n",
            "remote: Total 112 (delta 39), reused 49 (delta 13), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (112/112), 43.46 KiB | 1.17 MiB/s, done.\n",
            "Resolving deltas: 100% (39/39), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%cd Deep_Reinforcement_Learning_Recommenders"
      ],
      "metadata": {
        "id": "IMtLLtgNBxq2"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjVzjEzjnZBq",
        "outputId": "c3e55221-17e9-4c2d-be21-e457b55fa050"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mDRL_Recommenders\u001b[0m/  LICENSE  README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!git pull"
      ],
      "metadata": {
        "id": "8tbm8W6cnasM"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etZ9ckERnd-B",
        "outputId": "79ce8f64-4d5d-4ef5-f44e-3932276c6c00"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/GoogleDrive/MyDrive/DUKE/AIPI531_DRL/Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Run Preprocessing Files (Replay_Buffer and Pop) on cleaned dataset"
      ],
      "metadata": {
        "id": "k39_I2DPWvTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset2_Diginetica/src/replay_buffer_v1.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_mrfuEol0HR",
        "outputId": "429b111f-bce6-4ff4-edb4-f227c4d6c270"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-03 16:57:40.814396: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-03 16:57:42.759888: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-05-03 16:57:42.760103: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-05-03 16:57:42.760130: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset2_Diginetica/src/pop_v1.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NFKYud4m38e",
        "outputId": "3a83070a-849b-487e-97e8-31796a57d270"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "1.0\n",
            "2.0\n",
            "3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: SNQN Model with SASRec (without item features)"
      ],
      "metadata": {
        "id": "6eSUuZiuYw0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "tac = time.time()\n",
        "\n",
        "!python Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset2_Diginetica/src/SNQN_v1.py --model=SASRec --epoch=1\n",
        "\n",
        "tic = time.time()\n",
        "print(f\"Time to run 15 epochs: {np.round((tic-tac)/60,2)} minutes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NmkTCxAn2OL",
        "outputId": "fb848f9e-d348-47eb-c65a-220ee464a8dc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-02 10:38:11.128548: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-02 10:38:12.730211: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-05-02 10:38:12.730329: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-05-02 10:38:12.730351: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "Built with cuda: <function is_built_with_cuda at 0x7f32e7989090>\n",
            "2023-05-02 10:38:17.544981: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "/device:GPU:0\n",
            "the loss in 200th batch is: 10.906185\n",
            "the loss in 400th batch is: 10.602740\n",
            "the loss in 600th batch is: 10.454380\n",
            "the loss in 800th batch is: 10.386357\n",
            "the loss in 1000th batch is: 10.375382\n",
            "Time to run 15 epochs: 3.63 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "tac = time.time()\n",
        "\n",
        "!python Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset2_Diginetica/src/SNQN_v1.py --model=SASRec --epoch=15\n",
        "\n",
        "tic = time.time()\n",
        "print(f\"Time to run 15 epochs: {np.round((tic-tac)/60,2)} minutes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yio3k4iQE3Ot",
        "outputId": "1dc5989e-155f-42f0-a97e-9eeab17a09e4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-02 12:57:21.915063: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-02 12:57:23.121795: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-05-02 12:57:23.121896: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-05-02 12:57:23.121915: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "Built with cuda: <function is_built_with_cuda at 0x7fb5c92c1090>\n",
            "2023-05-02 12:57:26.721283: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "/device:GPU:0\n",
            "the loss in 200th batch is: 10.923100\n",
            "the loss in 400th batch is: 10.630077\n",
            "the loss in 600th batch is: 10.429308\n",
            "the loss in 800th batch is: 10.464210\n",
            "the loss in 1000th batch is: 10.310783\n",
            "the loss in 1200th batch is: 10.415055\n",
            "the loss in 1400th batch is: 10.206158\n",
            "the loss in 1600th batch is: 10.227198\n",
            "the loss in 1800th batch is: 10.247766\n",
            "the loss in 2000th batch is: 10.408216\n",
            "the loss in 2200th batch is: 10.025861\n",
            "the loss in 2400th batch is: 9.991205\n",
            "the loss in 2600th batch is: 9.858895\n",
            "the loss in 2800th batch is: 9.938691\n",
            "the loss in 3000th batch is: 9.982466\n",
            "the loss in 3200th batch is: 9.694011\n",
            "the loss in 3400th batch is: 9.354127\n",
            "the loss in 3600th batch is: 10.049913\n",
            "the loss in 3800th batch is: 9.485037\n",
            "the loss in 4000th batch is: 9.553217\n",
            "#############################################################\n",
            "total clicks: 36997, total purchase:958\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 1.400000\n",
            "clicks hr ndcg @ 5 : 0.000189, 0.000105\n",
            "purchase hr and ndcg @5 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 8.600000\n",
            "clicks hr ndcg @ 10 : 0.000351, 0.000157\n",
            "purchase hr and ndcg @10 : 0.006263, 0.002074\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 8.600000\n",
            "clicks hr ndcg @ 15 : 0.000351, 0.000157\n",
            "purchase hr and ndcg @15 : 0.006263, 0.002074\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 10.200000\n",
            "clicks hr ndcg @ 20 : 0.000432, 0.000176\n",
            "purchase hr and ndcg @20 : 0.007307, 0.002320\n",
            "#############################################################\n",
            "the loss in 4200th batch is: 9.336964\n",
            "the loss in 4400th batch is: 9.525497\n",
            "the loss in 4600th batch is: 9.260778\n",
            "the loss in 4800th batch is: 9.451767\n",
            "the loss in 5000th batch is: 9.067316\n",
            "the loss in 5200th batch is: 8.535167\n",
            "the loss in 5400th batch is: 9.012516\n",
            "the loss in 5600th batch is: 8.758296\n",
            "the loss in 5800th batch is: 8.541080\n",
            "the loss in 6000th batch is: 8.476103\n",
            "the loss in 6200th batch is: 8.393769\n",
            "the loss in 6400th batch is: 8.570356\n",
            "the loss in 6600th batch is: 7.899764\n",
            "the loss in 6800th batch is: 7.970001\n",
            "the loss in 7000th batch is: 8.286880\n",
            "the loss in 7200th batch is: 8.301036\n",
            "the loss in 7400th batch is: 8.076205\n",
            "the loss in 7600th batch is: 7.803116\n",
            "the loss in 7800th batch is: 7.737628\n",
            "the loss in 8000th batch is: 7.684445\n",
            "#############################################################\n",
            "total clicks: 36997, total purchase:958\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 0.200000\n",
            "clicks hr ndcg @ 5 : 0.000027, 0.000012\n",
            "purchase hr and ndcg @5 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 2.200000\n",
            "clicks hr ndcg @ 10 : 0.000297, 0.000092\n",
            "purchase hr and ndcg @10 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 3.000000\n",
            "clicks hr ndcg @ 15 : 0.000405, 0.000120\n",
            "purchase hr and ndcg @15 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 3.600000\n",
            "clicks hr ndcg @ 20 : 0.000487, 0.000139\n",
            "purchase hr and ndcg @20 : 0.000000, 0.000000\n",
            "#############################################################\n",
            "the loss in 8200th batch is: 7.891809\n",
            "the loss in 8400th batch is: 8.015640\n",
            "the loss in 8600th batch is: 7.534496\n",
            "the loss in 8800th batch is: 7.506631\n",
            "the loss in 9000th batch is: 7.307168\n",
            "the loss in 9200th batch is: 7.294685\n",
            "the loss in 9400th batch is: 7.306845\n",
            "the loss in 9600th batch is: 7.427745\n",
            "the loss in 9800th batch is: 6.934827\n",
            "the loss in 10000th batch is: 7.127344\n",
            "the loss in 10200th batch is: 6.659376\n",
            "the loss in 10400th batch is: 6.658031\n",
            "the loss in 10600th batch is: 6.617781\n",
            "the loss in 10800th batch is: 6.380960\n",
            "the loss in 11000th batch is: 6.480474\n",
            "the loss in 11200th batch is: 6.672533\n",
            "the loss in 11400th batch is: 6.285317\n",
            "the loss in 11600th batch is: 6.590562\n",
            "the loss in 11800th batch is: 6.613188\n",
            "the loss in 12000th batch is: 6.807252\n",
            "#############################################################\n",
            "total clicks: 36997, total purchase:958\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 1.000000\n",
            "clicks hr ndcg @ 5 : 0.000135, 0.000071\n",
            "purchase hr and ndcg @5 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 2.800000\n",
            "clicks hr ndcg @ 10 : 0.000243, 0.000106\n",
            "purchase hr and ndcg @10 : 0.001044, 0.000348\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 3.600000\n",
            "clicks hr ndcg @ 15 : 0.000351, 0.000134\n",
            "purchase hr and ndcg @15 : 0.001044, 0.000348\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 4.000000\n",
            "clicks hr ndcg @ 20 : 0.000405, 0.000147\n",
            "purchase hr and ndcg @20 : 0.001044, 0.000348\n",
            "#############################################################\n",
            "the loss in 12200th batch is: 6.242462\n",
            "the loss in 12400th batch is: 5.948853\n",
            "the loss in 12600th batch is: 6.427258\n",
            "the loss in 12800th batch is: 6.769906\n",
            "the loss in 13000th batch is: 5.716484\n",
            "the loss in 13200th batch is: 6.378318\n",
            "the loss in 13400th batch is: 5.935990\n",
            "the loss in 13600th batch is: 6.013708\n",
            "the loss in 13800th batch is: 6.402977\n",
            "the loss in 14000th batch is: 6.116917\n",
            "the loss in 14200th batch is: 6.031576\n",
            "the loss in 14400th batch is: 5.844960\n",
            "the loss in 14600th batch is: 6.348683\n",
            "the loss in 14800th batch is: 5.559638\n",
            "the loss in 15000th batch is: 5.722009\n",
            "the loss in 15200th batch is: 5.492021\n",
            "the loss in 15400th batch is: 5.530194\n",
            "the loss in 15600th batch is: 5.661966\n",
            "the loss in 15800th batch is: 5.608703\n",
            "the loss in 16000th batch is: 5.027772\n",
            "#############################################################\n",
            "total clicks: 36997, total purchase:958\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 0.800000\n",
            "clicks hr ndcg @ 5 : 0.000108, 0.000068\n",
            "purchase hr and ndcg @5 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 2.800000\n",
            "clicks hr ndcg @ 10 : 0.000378, 0.000153\n",
            "purchase hr and ndcg @10 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 4.800000\n",
            "clicks hr ndcg @ 15 : 0.000649, 0.000226\n",
            "purchase hr and ndcg @15 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 6.800000\n",
            "clicks hr ndcg @ 20 : 0.000784, 0.000258\n",
            "purchase hr and ndcg @20 : 0.001044, 0.000246\n",
            "#############################################################\n",
            "the loss in 16200th batch is: 5.529750\n",
            "the loss in 16400th batch is: 5.537601\n",
            "the loss in 16600th batch is: 5.698741\n",
            "the loss in 16800th batch is: 5.631349\n",
            "the loss in 17000th batch is: 5.439548\n",
            "the loss in 17200th batch is: 5.553124\n",
            "the loss in 17400th batch is: 5.324698\n",
            "the loss in 17600th batch is: 5.288026\n",
            "Time to run 15 epochs: 64.07 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: SNQN Model with SASRec (with item features)"
      ],
      "metadata": {
        "id": "y1kDIr1gZDRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "tac = time.time()\n",
        "\n",
        "!python Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset2_Diginetica/src/SNQN_P.py --model=SASRec --epoch=1\n",
        "\n",
        "tic = time.time()\n",
        "print(f\"Time to run 15 epochs: {np.round((tic-tac)/60,2)} minutes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFUk8l-SvYy7",
        "outputId": "ba636036-db59-4f1d-d1e4-3c8f1d4e8257"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-03 17:10:18.583302: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-03 17:10:19.945234: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-05-03 17:10:19.945351: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-05-03 17:10:19.945385: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "Built with cuda: <function is_built_with_cuda at 0x7f115d671090>\n",
            "2023-05-03 17:10:23.513279: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "/device:GPU:0\n",
            "OUTPUT 2 SHAPE:  (None, 72222)\n",
            "w_f SHAPE:  (72222, 64)\n",
            "phi 2 SHAPE:  (None, 72222)\n",
            "final score SHAPE:  (None, 72222)\n",
            "ce_loss SHAPE:  (None,)\n",
            "OUTPUT 2 SHAPE:  (None, 72222)\n",
            "w_f SHAPE:  (72222, 64)\n",
            "phi 2 SHAPE:  (None, 72222)\n",
            "final score SHAPE:  (None, 72222)\n",
            "ce_loss SHAPE:  (None,)\n",
            "#############################################################\n",
            "total clicks: 36997, total purchase:958\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 1.400000\n",
            "clicks hr ndcg @ 5 : 0.000189, 0.000091\n",
            "purchase hr and ndcg @5 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 1.800000\n",
            "clicks hr ndcg @ 10 : 0.000243, 0.000107\n",
            "purchase hr and ndcg @10 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 2.200000\n",
            "clicks hr ndcg @ 15 : 0.000297, 0.000122\n",
            "purchase hr and ndcg @15 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 3.800000\n",
            "clicks hr ndcg @ 20 : 0.000514, 0.000173\n",
            "purchase hr and ndcg @20 : 0.000000, 0.000000\n",
            "#############################################################\n",
            "the loss in 200th batch is: 11.063989\n",
            "the loss in 400th batch is: 10.617736\n",
            "the loss in 600th batch is: 10.473333\n",
            "the loss in 800th batch is: 10.543546\n",
            "the loss in 1000th batch is: 10.330119\n",
            "Time to run 15 epochs: 9.74 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "tac = time.time()\n",
        "\n",
        "!python Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset2_Diginetica/src/SNQN_P.py --model=SASRec --epoch=15\n",
        "\n",
        "tic = time.time()\n",
        "print(f\"Time to run 15 epochs: {np.round((tic-tac)/60,2)} minutes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIiFP92CoU2u",
        "outputId": "a60dae3d-19a3-47ed-c7d3-93beb2ae3dbc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-03 17:20:41.555610: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-03 17:20:43.686456: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-05-03 17:20:43.686628: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-05-03 17:20:43.686650: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "Built with cuda: <function is_built_with_cuda at 0x7facbb021090>\n",
            "2023-05-03 17:20:48.046532: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "/device:GPU:0\n",
            "OUTPUT 2 SHAPE:  (None, 72222)\n",
            "w_f SHAPE:  (72222, 64)\n",
            "phi 2 SHAPE:  (None, 72222)\n",
            "final score SHAPE:  (None, 72222)\n",
            "ce_loss SHAPE:  (None,)\n",
            "OUTPUT 2 SHAPE:  (None, 72222)\n",
            "w_f SHAPE:  (72222, 64)\n",
            "phi 2 SHAPE:  (None, 72222)\n",
            "final score SHAPE:  (None, 72222)\n",
            "ce_loss SHAPE:  (None,)\n",
            "#############################################################\n",
            "total clicks: 36997, total purchase:958\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 1.600000\n",
            "clicks hr ndcg @ 5 : 0.000216, 0.000101\n",
            "purchase hr and ndcg @5 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 2.000000\n",
            "clicks hr ndcg @ 10 : 0.000270, 0.000118\n",
            "purchase hr and ndcg @10 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 2.800000\n",
            "clicks hr ndcg @ 15 : 0.000378, 0.000146\n",
            "purchase hr and ndcg @15 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 4.600000\n",
            "clicks hr ndcg @ 20 : 0.000622, 0.000204\n",
            "purchase hr and ndcg @20 : 0.000000, 0.000000\n",
            "#############################################################\n",
            "the loss in 200th batch is: 11.078665\n",
            "the loss in 400th batch is: 10.468855\n",
            "the loss in 600th batch is: 10.550458\n",
            "the loss in 800th batch is: 10.364820\n",
            "the loss in 1000th batch is: 10.434830\n",
            "the loss in 1200th batch is: 10.149935\n",
            "the loss in 1400th batch is: 10.196102\n",
            "the loss in 1600th batch is: 10.040846\n",
            "the loss in 1800th batch is: 9.870436\n",
            "the loss in 2000th batch is: 9.778118\n",
            "the loss in 2200th batch is: 9.804740\n",
            "the loss in 2400th batch is: 9.807614\n",
            "the loss in 2600th batch is: 9.598760\n",
            "the loss in 2800th batch is: 9.569325\n",
            "the loss in 3000th batch is: 9.584492\n",
            "the loss in 3200th batch is: 9.362872\n",
            "the loss in 3400th batch is: 9.445540\n",
            "the loss in 3600th batch is: 8.824454\n",
            "the loss in 3800th batch is: 8.912210\n",
            "the loss in 4000th batch is: 9.074606\n",
            "#############################################################\n",
            "total clicks: 36997, total purchase:958\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 751.800000\n",
            "clicks hr ndcg @ 5 : 0.086196, 0.060503\n",
            "purchase hr and ndcg @5 : 0.118998, 0.084209\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 1052.400000\n",
            "clicks hr ndcg @ 10 : 0.122632, 0.072282\n",
            "purchase hr and ndcg @10 : 0.151357, 0.094784\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 1222.200000\n",
            "clicks hr ndcg @ 15 : 0.144093, 0.077953\n",
            "purchase hr and ndcg @15 : 0.162839, 0.097844\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 1335.800000\n",
            "clicks hr ndcg @ 20 : 0.158634, 0.081388\n",
            "purchase hr and ndcg @20 : 0.169102, 0.099334\n",
            "#############################################################\n",
            "the loss in 4200th batch is: 8.635911\n",
            "the loss in 4400th batch is: 8.530931\n",
            "the loss in 4600th batch is: 8.621290\n",
            "the loss in 4800th batch is: 8.409353\n",
            "the loss in 5000th batch is: 8.300646\n",
            "the loss in 5200th batch is: 8.261346\n",
            "the loss in 5400th batch is: 8.121585\n",
            "the loss in 5600th batch is: 8.075040\n",
            "the loss in 5800th batch is: 8.180552\n",
            "the loss in 6000th batch is: 8.392408\n",
            "the loss in 6200th batch is: 7.596923\n",
            "the loss in 6400th batch is: 7.762790\n",
            "the loss in 6600th batch is: 7.363431\n",
            "the loss in 6800th batch is: 7.673285\n",
            "the loss in 7000th batch is: 7.521556\n",
            "the loss in 7200th batch is: 7.465395\n",
            "the loss in 7400th batch is: 7.331930\n",
            "the loss in 7600th batch is: 7.040812\n",
            "the loss in 7800th batch is: 7.116755\n",
            "the loss in 8000th batch is: 7.132916\n",
            "#############################################################\n",
            "total clicks: 36997, total purchase:958\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 932.400000\n",
            "clicks hr ndcg @ 5 : 0.110198, 0.078260\n",
            "purchase hr and ndcg @5 : 0.122129, 0.084197\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 1304.400000\n",
            "clicks hr ndcg @ 10 : 0.154661, 0.092621\n",
            "purchase hr and ndcg @10 : 0.167015, 0.098873\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 1540.200000\n",
            "clicks hr ndcg @ 15 : 0.183420, 0.100227\n",
            "purchase hr and ndcg @15 : 0.191023, 0.105255\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 1731.200000\n",
            "clicks hr ndcg @ 20 : 0.206260, 0.105620\n",
            "purchase hr and ndcg @20 : 0.213987, 0.110704\n",
            "#############################################################\n",
            "the loss in 8200th batch is: 7.216875\n",
            "the loss in 8400th batch is: 6.998063\n",
            "the loss in 8600th batch is: 6.974887\n",
            "the loss in 8800th batch is: 6.870090\n",
            "the loss in 9000th batch is: 7.155300\n",
            "the loss in 9200th batch is: 7.051579\n",
            "the loss in 9400th batch is: 6.990838\n",
            "the loss in 9600th batch is: 6.847420\n",
            "the loss in 9800th batch is: 6.417974\n",
            "the loss in 10000th batch is: 6.645166\n",
            "the loss in 10200th batch is: 6.549894\n",
            "the loss in 10400th batch is: 6.877969\n",
            "the loss in 10600th batch is: 6.471658\n",
            "the loss in 10800th batch is: 6.477733\n",
            "the loss in 11000th batch is: 6.046476\n",
            "the loss in 11200th batch is: 6.731045\n",
            "the loss in 11400th batch is: 6.822513\n",
            "the loss in 11600th batch is: 6.227319\n",
            "the loss in 11800th batch is: 6.448014\n",
            "the loss in 12000th batch is: 5.844338\n",
            "#############################################################\n",
            "total clicks: 36997, total purchase:958\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 943.400000\n",
            "clicks hr ndcg @ 5 : 0.113036, 0.081236\n",
            "purchase hr and ndcg @5 : 0.111691, 0.078424\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 1339.000000\n",
            "clicks hr ndcg @ 10 : 0.160148, 0.096400\n",
            "purchase hr and ndcg @10 : 0.160752, 0.094519\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 1600.200000\n",
            "clicks hr ndcg @ 15 : 0.191934, 0.104792\n",
            "purchase hr and ndcg @15 : 0.187891, 0.101722\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 1799.400000\n",
            "clicks hr ndcg @ 20 : 0.215747, 0.110410\n",
            "purchase hr and ndcg @20 : 0.211900, 0.107409\n",
            "#############################################################\n",
            "the loss in 12200th batch is: 6.244498\n",
            "the loss in 12400th batch is: 5.913230\n",
            "the loss in 12600th batch is: 6.299222\n",
            "the loss in 12800th batch is: 6.282725\n",
            "the loss in 13000th batch is: 6.206264\n",
            "the loss in 13200th batch is: 6.112100\n",
            "the loss in 13400th batch is: 5.839002\n",
            "the loss in 13600th batch is: 6.064917\n",
            "the loss in 13800th batch is: 5.874168\n",
            "the loss in 14000th batch is: 5.626927\n",
            "the loss in 14200th batch is: 5.787145\n",
            "the loss in 14400th batch is: 6.144256\n",
            "the loss in 14600th batch is: 6.132226\n",
            "the loss in 14800th batch is: 6.163404\n",
            "the loss in 15000th batch is: 6.075842\n",
            "the loss in 15200th batch is: 6.069593\n",
            "the loss in 15400th batch is: 5.772510\n",
            "the loss in 15600th batch is: 6.064425\n",
            "the loss in 15800th batch is: 5.831459\n",
            "the loss in 16000th batch is: 6.066615\n",
            "#############################################################\n",
            "total clicks: 36997, total purchase:958\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 951.800000\n",
            "clicks hr ndcg @ 5 : 0.113090, 0.081594\n",
            "purchase hr and ndcg @5 : 0.120042, 0.081328\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 1338.400000\n",
            "clicks hr ndcg @ 10 : 0.160067, 0.096746\n",
            "purchase hr and ndcg @10 : 0.160752, 0.094191\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 1605.200000\n",
            "clicks hr ndcg @ 15 : 0.192205, 0.105245\n",
            "purchase hr and ndcg @15 : 0.191023, 0.102181\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 1806.400000\n",
            "clicks hr ndcg @ 20 : 0.217099, 0.111118\n",
            "purchase hr and ndcg @20 : 0.208768, 0.106387\n",
            "#############################################################\n",
            "the loss in 16200th batch is: 5.677097\n",
            "the loss in 16400th batch is: 5.777821\n",
            "the loss in 16600th batch is: 5.675600\n",
            "the loss in 16800th batch is: 5.836801\n",
            "the loss in 17000th batch is: 5.644711\n",
            "the loss in 17200th batch is: 5.601398\n",
            "the loss in 17400th batch is: 5.792737\n",
            "the loss in 17600th batch is: 5.918202\n",
            "Time to run 15 epochs: 88.12 minutes\n"
          ]
        }
      ]
    }
  ]
}