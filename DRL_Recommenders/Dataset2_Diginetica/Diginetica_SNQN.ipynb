{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpIiAR34HytBe4tJtVAZ87",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kashafali8/Deep_Reinforcement_Learning_Recommenders/blob/main/DRL_Recommenders/Dataset2_Diginetica/Diginetica_SNQN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WX21I_X_jp8-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/GoogleDrive')\n",
        "PROJ_DIR = '/content/GoogleDrive/My Drive/DUKE/AIPI531_DRL/Project'\n",
        "# change current directory after mounting\n",
        "%cd $PROJ_DIR\n",
        "! ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3OPLMWlkBRk",
        "outputId": "cb4da2c2-ab46-4d52-fbf2-a0a28691992e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/GoogleDrive\n",
            "/content/GoogleDrive/My Drive/DUKE/AIPI531_DRL/Project\n",
            " Data\t\t\t\t\t    report_SNQN.txt\n",
            " Deep_Reinforcement_Learning_Recommenders   SA2C_code\n",
            " Diginetica_Preprocess.ipynb\t\t    SA2C_code.zip\n",
            "'Diginetica_SNQN (1).ipynb'\t\t   'Source Code Implementation.ipynb'\n",
            " Diginetica_SNQN.ipynb\t\t\t    Untitled0.ipynb\n",
            " pop_dict.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! apt-get install git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OskxNDEkTtM",
        "outputId": "f292ce29-4bff-4b6d-bb5f-4d768dc898cb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "git is already the newest version (1:2.25.1-1ubuntu3.11).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/kashafali8/Deep_Reinforcement_Learning_Recommenders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QikIEW2ZkoIJ",
        "outputId": "a04ac46c-dc85-41d9-edfc-159dc6014e32"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Deep_Reinforcement_Learning_Recommenders'...\n",
            "remote: Enumerating objects: 112, done.\u001b[K\n",
            "remote: Counting objects: 100% (112/112), done.\u001b[K\n",
            "remote: Compressing objects: 100% (91/91), done.\u001b[K\n",
            "remote: Total 112 (delta 39), reused 49 (delta 13), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (112/112), 43.46 KiB | 1.17 MiB/s, done.\n",
            "Resolving deltas: 100% (39/39), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset2_Diginetica/src/replay_buffer_v1.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_mrfuEol0HR",
        "outputId": "7c3788c4-4a1c-40b3-8a56-ea0d43be49b5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-03 01:10:37.904340: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-03 01:10:39.562307: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Deep_Reinforcement_Learning_Recommenders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQ12ezObnP1t",
        "outputId": "8ef42f52-9439-463c-acee-57b9efccefac"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/GoogleDrive/MyDrive/DUKE/AIPI531_DRL/Project/Deep_Reinforcement_Learning_Recommenders\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjVzjEzjnZBq",
        "outputId": "39155ed8-a554-4b91-94f0-655c239f9491"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mDRL_Recommenders\u001b[0m/  LICENSE  README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tbm8W6cnasM",
        "outputId": "7ceec636-f6c1-49e4-cfc1-1c2eec1a80ed"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 23, done.\u001b[K\n",
            "remote: Counting objects:   4% (1/23)\u001b[K\rremote: Counting objects:   8% (2/23)\u001b[K\rremote: Counting objects:  13% (3/23)\u001b[K\rremote: Counting objects:  17% (4/23)\u001b[K\rremote: Counting objects:  21% (5/23)\u001b[K\rremote: Counting objects:  26% (6/23)\u001b[K\rremote: Counting objects:  30% (7/23)\u001b[K\rremote: Counting objects:  34% (8/23)\u001b[K\rremote: Counting objects:  39% (9/23)\u001b[K\rremote: Counting objects:  43% (10/23)\u001b[K\rremote: Counting objects:  47% (11/23)\u001b[K\rremote: Counting objects:  52% (12/23)\u001b[K\rremote: Counting objects:  56% (13/23)\u001b[K\rremote: Counting objects:  60% (14/23)\u001b[K\rremote: Counting objects:  65% (15/23)\u001b[K\rremote: Counting objects:  69% (16/23)\u001b[K\rremote: Counting objects:  73% (17/23)\u001b[K\rremote: Counting objects:  78% (18/23)\u001b[K\rremote: Counting objects:  82% (19/23)\u001b[K\rremote: Counting objects:  86% (20/23)\u001b[K\rremote: Counting objects:  91% (21/23)\u001b[K\rremote: Counting objects:  95% (22/23)\u001b[K\rremote: Counting objects: 100% (23/23)\u001b[K\rremote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects:   8% (1/12)\u001b[K\rremote: Compressing objects:  16% (2/12)\u001b[K\rremote: Compressing objects:  25% (3/12)\u001b[K\rremote: Compressing objects:  33% (4/12)\u001b[K\rremote: Compressing objects:  41% (5/12)\u001b[K\rremote: Compressing objects:  50% (6/12)\u001b[K\rremote: Compressing objects:  58% (7/12)\u001b[K\rremote: Compressing objects:  66% (8/12)\u001b[K\rremote: Compressing objects:  75% (9/12)\u001b[K\rremote: Compressing objects:  83% (10/12)\u001b[K\rremote: Compressing objects:  91% (11/12)\u001b[K\rremote: Compressing objects: 100% (12/12)\u001b[K\rremote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 18 (delta 8), reused 16 (delta 6), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (18/18), 7.33 KiB | 8.00 KiB/s, done.\n",
            "From https://github.com/kashafali8/Deep_Reinforcement_Learning_Recommenders\n",
            "   fac0262..9ef0e8a  main       -> origin/main\n",
            "Updating fac0262..9ef0e8a\n",
            "Fast-forward\n",
            " DRL_Recommenders/Dataset2_Diginetica/src/SNQN_A.py | 637 \u001b[32m+++++++++++++++++++++\u001b[m\n",
            " .../Dataset2_Diginetica/src/SNQN_v1.py             |  22 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 2 files changed, 652 insertions(+), 7 deletions(-)\n",
            " create mode 100644 DRL_Recommenders/Dataset2_Diginetica/src/SNQN_A.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etZ9ckERnd-B",
        "outputId": "d31b8c1b-2cda-48de-f107-61b10341f1a8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/GoogleDrive/MyDrive/DUKE/AIPI531_DRL/Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset2_Diginetica/src/pop_v1.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NFKYud4m38e",
        "outputId": "dc19a87d-6520-428a-9519-aafa6c2667e0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "1.0\n",
            "2.0\n",
            "3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pandas trfl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJzXlAz7nPfL",
        "outputId": "8777ffaa-eaaa-4c04-bfbd-673c21cc4bef"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Collecting trfl\n",
            "  Downloading trfl-1.2.0-py3-none-any.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from trfl) (1.16.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from trfl) (1.4.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from trfl) (1.14.1)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from trfl) (0.1.8)\n",
            "Installing collected packages: trfl\n",
            "Successfully installed trfl-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-gpu==2.11.0\n",
        "# !pip install numpy==1.19.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eshLNsgp_K0A",
        "outputId": "46d22978-e773-412e-98d6-a88a689e009f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-gpu==2.11.0\n",
            "  Downloading tensorflow_gpu-2.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11.0) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11.0) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11.0) (3.8.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11.0) (2.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11.0) (16.0.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11.0) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11.0) (23.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11.0) (3.19.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11.0) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11.0) (2.11.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11.0) (2.11.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11.0) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11.0) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.11.0) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow-gpu==2.11.0) (0.40.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu==2.11.0) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu==2.11.0) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu==2.11.0) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu==2.11.0) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu==2.11.0) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu==2.11.0) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu==2.11.0) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu==2.11.0) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu==2.11.0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu==2.11.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-gpu==2.11.0) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu==2.11.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu==2.11.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu==2.11.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu==2.11.0) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow-gpu==2.11.0) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu==2.11.0) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-gpu==2.11.0) (3.2.2)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "  Attempting uninstall: tensorflow-gpu\n",
            "    Found existing installation: tensorflow-gpu 2.8.0\n",
            "    Uninstalling tensorflow-gpu-2.8.0:\n",
            "      Successfully uninstalled tensorflow-gpu-2.8.0\n",
            "Successfully installed tensorflow-gpu-2.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.11.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgBH0crIAShy",
        "outputId": "09531953-e362-4b2b-f7c4-2c55a0df7b45"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.11.0\n",
            "  Downloading tensorflow-2.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (3.8.0)\n",
            "Collecting keras<2.12,>=2.11.0 (from tensorflow==2.11.0)\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (16.0.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (23.1)\n",
            "Collecting protobuf<3.20,>=3.9.2 (from tensorflow==2.11.0)\n",
            "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (1.16.0)\n",
            "Collecting tensorboard<2.12,>=2.11 (from tensorflow==2.11.0)\n",
            "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m105.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.12,>=2.11.0 (from tensorflow==2.11.0)\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.11.0) (0.40.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.2.2)\n",
            "Installing collected packages: tensorflow-estimator, protobuf, keras, tensorboard, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-gpu 2.8.0 requires keras<2.9,>=2.8.0rc0, but you have keras 2.11.0 which is incompatible.\n",
            "tensorflow-gpu 2.8.0 requires tensorboard<2.9,>=2.8, but you have tensorboard 2.11.2 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-2.11.0 protobuf-3.19.6 tensorboard-2.11.2 tensorflow-2.11.0 tensorflow-estimator-2.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.19.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgyfhnhB_aFK",
        "outputId": "0b660e6a-8f03-4468-9597-3fb332ec8dfc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy==1.19.5\n",
            "  Using cached numpy-1.19.5.zip (7.3 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: numpy\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for numpy \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for numpy (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for numpy\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build numpy\n",
            "\u001b[31mERROR: Could not build wheels for numpy, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "tac = time.time()\n",
        "\n",
        "!python Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset2_Diginetica/src/SNQN_v1.py --model=SASRec --epoch=1\n",
        "\n",
        "tic = time.time()\n",
        "print(f\"Time to run 15 epochs: {np.round((tic-tac)/60,2)} minutes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NmkTCxAn2OL",
        "outputId": "fb848f9e-d348-47eb-c65a-220ee464a8dc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-02 10:38:11.128548: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-02 10:38:12.730211: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-05-02 10:38:12.730329: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-05-02 10:38:12.730351: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "Built with cuda: <function is_built_with_cuda at 0x7f32e7989090>\n",
            "2023-05-02 10:38:17.544981: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "/device:GPU:0\n",
            "the loss in 200th batch is: 10.906185\n",
            "the loss in 400th batch is: 10.602740\n",
            "the loss in 600th batch is: 10.454380\n",
            "the loss in 800th batch is: 10.386357\n",
            "the loss in 1000th batch is: 10.375382\n",
            "Time to run 15 epochs: 3.63 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "tac = time.time()\n",
        "\n",
        "!python Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset2_Diginetica/src/SNQN_v1.py --model=SASRec --epoch=15\n",
        "\n",
        "tic = time.time()\n",
        "print(f\"Time to run 15 epochs: {np.round((tic-tac)/60,2)} minutes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yio3k4iQE3Ot",
        "outputId": "1dc5989e-155f-42f0-a97e-9eeab17a09e4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-02 12:57:21.915063: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-02 12:57:23.121795: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-05-02 12:57:23.121896: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-05-02 12:57:23.121915: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "Built with cuda: <function is_built_with_cuda at 0x7fb5c92c1090>\n",
            "2023-05-02 12:57:26.721283: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "/device:GPU:0\n",
            "the loss in 200th batch is: 10.923100\n",
            "the loss in 400th batch is: 10.630077\n",
            "the loss in 600th batch is: 10.429308\n",
            "the loss in 800th batch is: 10.464210\n",
            "the loss in 1000th batch is: 10.310783\n",
            "the loss in 1200th batch is: 10.415055\n",
            "the loss in 1400th batch is: 10.206158\n",
            "the loss in 1600th batch is: 10.227198\n",
            "the loss in 1800th batch is: 10.247766\n",
            "the loss in 2000th batch is: 10.408216\n",
            "the loss in 2200th batch is: 10.025861\n",
            "the loss in 2400th batch is: 9.991205\n",
            "the loss in 2600th batch is: 9.858895\n",
            "the loss in 2800th batch is: 9.938691\n",
            "the loss in 3000th batch is: 9.982466\n",
            "the loss in 3200th batch is: 9.694011\n",
            "the loss in 3400th batch is: 9.354127\n",
            "the loss in 3600th batch is: 10.049913\n",
            "the loss in 3800th batch is: 9.485037\n",
            "the loss in 4000th batch is: 9.553217\n",
            "#############################################################\n",
            "total clicks: 36997, total purchase:958\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 1.400000\n",
            "clicks hr ndcg @ 5 : 0.000189, 0.000105\n",
            "purchase hr and ndcg @5 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 8.600000\n",
            "clicks hr ndcg @ 10 : 0.000351, 0.000157\n",
            "purchase hr and ndcg @10 : 0.006263, 0.002074\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 8.600000\n",
            "clicks hr ndcg @ 15 : 0.000351, 0.000157\n",
            "purchase hr and ndcg @15 : 0.006263, 0.002074\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 10.200000\n",
            "clicks hr ndcg @ 20 : 0.000432, 0.000176\n",
            "purchase hr and ndcg @20 : 0.007307, 0.002320\n",
            "#############################################################\n",
            "the loss in 4200th batch is: 9.336964\n",
            "the loss in 4400th batch is: 9.525497\n",
            "the loss in 4600th batch is: 9.260778\n",
            "the loss in 4800th batch is: 9.451767\n",
            "the loss in 5000th batch is: 9.067316\n",
            "the loss in 5200th batch is: 8.535167\n",
            "the loss in 5400th batch is: 9.012516\n",
            "the loss in 5600th batch is: 8.758296\n",
            "the loss in 5800th batch is: 8.541080\n",
            "the loss in 6000th batch is: 8.476103\n",
            "the loss in 6200th batch is: 8.393769\n",
            "the loss in 6400th batch is: 8.570356\n",
            "the loss in 6600th batch is: 7.899764\n",
            "the loss in 6800th batch is: 7.970001\n",
            "the loss in 7000th batch is: 8.286880\n",
            "the loss in 7200th batch is: 8.301036\n",
            "the loss in 7400th batch is: 8.076205\n",
            "the loss in 7600th batch is: 7.803116\n",
            "the loss in 7800th batch is: 7.737628\n",
            "the loss in 8000th batch is: 7.684445\n",
            "#############################################################\n",
            "total clicks: 36997, total purchase:958\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 0.200000\n",
            "clicks hr ndcg @ 5 : 0.000027, 0.000012\n",
            "purchase hr and ndcg @5 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 2.200000\n",
            "clicks hr ndcg @ 10 : 0.000297, 0.000092\n",
            "purchase hr and ndcg @10 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 3.000000\n",
            "clicks hr ndcg @ 15 : 0.000405, 0.000120\n",
            "purchase hr and ndcg @15 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 3.600000\n",
            "clicks hr ndcg @ 20 : 0.000487, 0.000139\n",
            "purchase hr and ndcg @20 : 0.000000, 0.000000\n",
            "#############################################################\n",
            "the loss in 8200th batch is: 7.891809\n",
            "the loss in 8400th batch is: 8.015640\n",
            "the loss in 8600th batch is: 7.534496\n",
            "the loss in 8800th batch is: 7.506631\n",
            "the loss in 9000th batch is: 7.307168\n",
            "the loss in 9200th batch is: 7.294685\n",
            "the loss in 9400th batch is: 7.306845\n",
            "the loss in 9600th batch is: 7.427745\n",
            "the loss in 9800th batch is: 6.934827\n",
            "the loss in 10000th batch is: 7.127344\n",
            "the loss in 10200th batch is: 6.659376\n",
            "the loss in 10400th batch is: 6.658031\n",
            "the loss in 10600th batch is: 6.617781\n",
            "the loss in 10800th batch is: 6.380960\n",
            "the loss in 11000th batch is: 6.480474\n",
            "the loss in 11200th batch is: 6.672533\n",
            "the loss in 11400th batch is: 6.285317\n",
            "the loss in 11600th batch is: 6.590562\n",
            "the loss in 11800th batch is: 6.613188\n",
            "the loss in 12000th batch is: 6.807252\n",
            "#############################################################\n",
            "total clicks: 36997, total purchase:958\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 1.000000\n",
            "clicks hr ndcg @ 5 : 0.000135, 0.000071\n",
            "purchase hr and ndcg @5 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 2.800000\n",
            "clicks hr ndcg @ 10 : 0.000243, 0.000106\n",
            "purchase hr and ndcg @10 : 0.001044, 0.000348\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 3.600000\n",
            "clicks hr ndcg @ 15 : 0.000351, 0.000134\n",
            "purchase hr and ndcg @15 : 0.001044, 0.000348\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 4.000000\n",
            "clicks hr ndcg @ 20 : 0.000405, 0.000147\n",
            "purchase hr and ndcg @20 : 0.001044, 0.000348\n",
            "#############################################################\n",
            "the loss in 12200th batch is: 6.242462\n",
            "the loss in 12400th batch is: 5.948853\n",
            "the loss in 12600th batch is: 6.427258\n",
            "the loss in 12800th batch is: 6.769906\n",
            "the loss in 13000th batch is: 5.716484\n",
            "the loss in 13200th batch is: 6.378318\n",
            "the loss in 13400th batch is: 5.935990\n",
            "the loss in 13600th batch is: 6.013708\n",
            "the loss in 13800th batch is: 6.402977\n",
            "the loss in 14000th batch is: 6.116917\n",
            "the loss in 14200th batch is: 6.031576\n",
            "the loss in 14400th batch is: 5.844960\n",
            "the loss in 14600th batch is: 6.348683\n",
            "the loss in 14800th batch is: 5.559638\n",
            "the loss in 15000th batch is: 5.722009\n",
            "the loss in 15200th batch is: 5.492021\n",
            "the loss in 15400th batch is: 5.530194\n",
            "the loss in 15600th batch is: 5.661966\n",
            "the loss in 15800th batch is: 5.608703\n",
            "the loss in 16000th batch is: 5.027772\n",
            "#############################################################\n",
            "total clicks: 36997, total purchase:958\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 0.800000\n",
            "clicks hr ndcg @ 5 : 0.000108, 0.000068\n",
            "purchase hr and ndcg @5 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 2.800000\n",
            "clicks hr ndcg @ 10 : 0.000378, 0.000153\n",
            "purchase hr and ndcg @10 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 4.800000\n",
            "clicks hr ndcg @ 15 : 0.000649, 0.000226\n",
            "purchase hr and ndcg @15 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 6.800000\n",
            "clicks hr ndcg @ 20 : 0.000784, 0.000258\n",
            "purchase hr and ndcg @20 : 0.001044, 0.000246\n",
            "#############################################################\n",
            "the loss in 16200th batch is: 5.529750\n",
            "the loss in 16400th batch is: 5.537601\n",
            "the loss in 16600th batch is: 5.698741\n",
            "the loss in 16800th batch is: 5.631349\n",
            "the loss in 17000th batch is: 5.439548\n",
            "the loss in 17200th batch is: 5.553124\n",
            "the loss in 17400th batch is: 5.324698\n",
            "the loss in 17600th batch is: 5.288026\n",
            "Time to run 15 epochs: 64.07 minutes\n"
          ]
        }
      ]
    }
  ]
}