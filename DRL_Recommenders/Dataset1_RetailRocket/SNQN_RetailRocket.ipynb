{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1kOiAr9R-0cq-3S4XmrjS9YbYoKDdbzS8",
      "authorship_tag": "ABX9TyON68djrCMY1LUdH9Uu5YOJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kashafali8/Deep_Reinforcement_Learning_Recommenders/blob/main/DRL_Recommenders/Dataset_RR/SNQN_RetailRocket.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Requirements"
      ],
      "metadata": {
        "id": "oO_rM36J1qfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -R /content/Deep_Reinforcement_Learning_Recommenders"
      ],
      "metadata": {
        "id": "KLGINtuJw5NL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFEqHRgEwaQ2",
        "outputId": "52751c8b-0fa0-454f-f6eb-466b2df7ab1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Deep_Reinforcement_Learning_Recommenders'...\n",
            "remote: Enumerating objects: 437, done.\u001b[K\n",
            "remote: Counting objects: 100% (187/187), done.\u001b[K\n",
            "remote: Compressing objects: 100% (124/124), done.\u001b[K\n",
            "remote: Total 437 (delta 123), reused 115 (delta 59), pack-reused 250\u001b[K\n",
            "Receiving objects: 100% (437/437), 8.49 MiB | 15.92 MiB/s, done.\n",
            "Resolving deltas: 100% (235/235), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/kashafali8/Deep_Reinforcement_Learning_Recommenders.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install trfl\n",
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Mnz0DaTwrz3",
        "outputId": "747c7c3f-9d1b-4d08-9792-33d117325b1d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: trfl in /usr/local/lib/python3.10/dist-packages (1.2.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from trfl) (0.1.8)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from trfl) (1.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from trfl) (1.16.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from trfl) (1.14.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from trfl) (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.13)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.15)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/drive/MyDrive/kaggle.json /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsIgjOuT03f7",
        "outputId": "25c1c93a-29fa-46b4-f1cc-d778dca7c2a8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat '/content/drive/MyDrive/kaggle.json': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Data"
      ],
      "metadata": {
        "id": "4FFdpWTe1zyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d retailrocket/ecommerce-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTFuwbzTzWGa",
        "outputId": "3a32a7b5-3329-486e-b9d6-1017e21d4580"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ecommerce-dataset.zip to /content\n",
            " 95% 275M/291M [00:01<00:00, 142MB/s]\n",
            "100% 291M/291M [00:02<00:00, 148MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip ecommerce-dataset.zip -d Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nL-NFN9_0ph8",
        "outputId": "11bc74bd-ec1a-4078-d01a-98808607836d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ecommerce-dataset.zip\n",
            "  inflating: Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/data/category_tree.csv  \n",
            "  inflating: Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/data/events.csv  \n",
            "  inflating: Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/data/item_properties_part1.csv  \n",
            "  inflating: Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/data/item_properties_part2.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm ecommerce-dataset.zip"
      ],
      "metadata": {
        "id": "S8-Bj7Q11c4C"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess Data"
      ],
      "metadata": {
        "id": "AirMFwP813Tx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/replay_buffer.py --data /content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unvlx4tN1kGS",
        "outputId": "6e46a633-0d54-4e59-b117-651c8fcabbb6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting to pre-process data...\n",
            "\n",
            "Sorting and pickling data...\n",
            "\n",
            "Splitting data into train, validation, and test sets...\n",
            "\n",
            "Pickling train, validation, and test sets...\n",
            "\n",
            "Calculating item popularity and storing as dictionary...\n",
            "\n",
            "Generating replay buffer from train set...\n",
            "\n",
            "Pickling replay buffer...\n",
            "\n",
            "Pickling data statistics...\n",
            "\n",
            "Script completed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SNQN Without Item Features"
      ],
      "metadata": {
        "id": "LaRq_c3U6r0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python \"/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/SNQN_v1.py\" --model=SASRec --epoch=10 --data=\"/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/data/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ati3iQPQ2AOF",
        "outputId": "1f80a5b0-338d-4b29-c20a-29ab4c3f2b41"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-04 00:36:00.450955: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-05-04 00:36:00.505483: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-04 00:36:01.564354: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/SNQN_v1.py:178: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
            "  self.seq = tf.compat.v1.layers.dropout(self.seq,\n",
            "2023-05-04 00:36:03.478148: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n",
            "\t [[{{node Placeholder}}]]\n",
            "/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/SASRecModules.py:142: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  Q = tf.compat.v1.layers.dense(queries, num_units, activation=None) # (N, T_q, C)\n",
            "/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/SASRecModules.py:143: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  K = tf.compat.v1.layers.dense(keys, num_units, activation=None) # (N, T_k, C)\n",
            "/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/SASRecModules.py:144: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  V = tf.compat.v1.layers.dense(keys, num_units, activation=None) # (N, T_k, C)\n",
            "/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/SASRecModules.py:184: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
            "  outputs = tf.compat.v1.layers.dropout(outputs, rate=dropout_rate, training=tf.convert_to_tensor(value=is_training))\n",
            "2023-05-04 00:36:03.699037: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n",
            "\t [[{{node Placeholder}}]]\n",
            "/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/SASRecModules.py:223: UserWarning: `tf.layers.conv1d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv1D` instead.\n",
            "  outputs = tf.compat.v1.layers.conv1d(**params)\n",
            "/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/SASRecModules.py:224: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
            "  outputs = tf.compat.v1.layers.dropout(outputs, rate=dropout_rate, training=tf.convert_to_tensor(value=is_training))\n",
            "2023-05-04 00:36:03.755302: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n",
            "\t [[{{node Placeholder}}]]\n",
            "/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/SASRecModules.py:228: UserWarning: `tf.layers.conv1d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv1D` instead.\n",
            "  outputs = tf.compat.v1.layers.conv1d(**params)\n",
            "/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/SASRecModules.py:229: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
            "  outputs = tf.compat.v1.layers.dropout(outputs, rate=dropout_rate, training=tf.convert_to_tensor(value=is_training))\n",
            "2023-05-04 00:36:03.795315: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n",
            "\t [[{{node Placeholder}}]]\n",
            "/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/SNQN_v1.py:206: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n",
            "/content/Deep_Reinforcement_Learning_Recommenders/DRL_Recommenders/Dataset_RR/src/SNQN_v1.py:209: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output2= tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n",
            "2023-05-04 00:36:05.317764: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n",
            "\t [[{{node Placeholder_1}}]]\n",
            "2023-05-04 00:36:05.468690: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n",
            "\t [[{{node Placeholder_1}}]]\n",
            "2023-05-04 00:36:05.528186: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n",
            "\t [[{{node Placeholder_1}}]]\n",
            "2023-05-04 00:36:05.570593: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n",
            "\t [[{{node Placeholder_1}}]]\n",
            "2023-05-04 00:36:11.276507: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-05-04 00:36:11.276564: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38286 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n",
            "2023-05-04 00:36:11.325784: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
            "2023-05-04 00:36:13.340162: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
            "2023-05-04 00:36:14.641612: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8700\n",
            "the loss in 200th batch is: 10.980393\n",
            "the loss in 400th batch is: 10.787041\n",
            "the loss in 600th batch is: 10.560697\n",
            "the loss in 800th batch is: 10.684052\n",
            "the loss in 1000th batch is: 10.614722\n",
            "the loss in 1200th batch is: 10.494523\n",
            "the loss in 1400th batch is: 10.401383\n",
            "the loss in 1600th batch is: 10.391398\n",
            "the loss in 1800th batch is: 10.404767\n",
            "the loss in 2000th batch is: 10.136910\n",
            "the loss in 2200th batch is: 10.016370\n",
            "the loss in 2400th batch is: 10.149205\n",
            "the loss in 2600th batch is: 10.020928\n",
            "the loss in 2800th batch is: 9.987682\n",
            "the loss in 3000th batch is: 10.011055\n",
            "the loss in 3200th batch is: 9.821464\n",
            "the loss in 3400th batch is: 10.015401\n",
            "the loss in 3600th batch is: 10.094572\n",
            "the loss in 3800th batch is: 9.839685\n",
            "the loss in 4000th batch is: 9.878578\n",
            "#############################################################\n",
            "total clicks: 117015, total purchase:5578\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 16.800000\n",
            "clicks hr ndcg @ 5 : 0.000461, 0.000305\n",
            "purchase hr and ndcg @5 : 0.001076, 0.000900\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 27.200000\n",
            "clicks hr ndcg @ 10 : 0.000820, 0.000420\n",
            "purchase hr and ndcg @10 : 0.001434, 0.001023\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 39.200000\n",
            "clicks hr ndcg @ 15 : 0.001077, 0.000488\n",
            "purchase hr and ndcg @15 : 0.002510, 0.001298\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 48.200000\n",
            "clicks hr ndcg @ 20 : 0.001248, 0.000529\n",
            "purchase hr and ndcg @20 : 0.003406, 0.001507\n",
            "#############################################################\n",
            "the loss in 4200th batch is: 9.987938\n",
            "the loss in 4400th batch is: 9.385244\n",
            "the loss in 4600th batch is: 9.343724\n",
            "the loss in 4800th batch is: 9.501023\n",
            "the loss in 5000th batch is: 9.643244\n",
            "the loss in 5200th batch is: 9.309292\n",
            "the loss in 5400th batch is: 9.340407\n",
            "the loss in 5600th batch is: 8.971385\n",
            "the loss in 5800th batch is: 8.973910\n",
            "the loss in 6000th batch is: 9.266643\n",
            "the loss in 6200th batch is: 9.057534\n",
            "the loss in 6400th batch is: 9.061030\n",
            "the loss in 6600th batch is: 8.784519\n",
            "the loss in 6800th batch is: 8.434833\n",
            "the loss in 7000th batch is: 8.816067\n",
            "the loss in 7200th batch is: 8.441645\n",
            "the loss in 7400th batch is: 8.849874\n",
            "the loss in 7600th batch is: 8.851354\n",
            "the loss in 7800th batch is: 8.256478\n",
            "the loss in 8000th batch is: 8.527381\n",
            "#############################################################\n",
            "total clicks: 117015, total purchase:5578\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 36.200000\n",
            "clicks hr ndcg @ 5 : 0.000906, 0.000583\n",
            "purchase hr and ndcg @5 : 0.002689, 0.001692\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 63.000000\n",
            "clicks hr ndcg @ 10 : 0.001496, 0.000772\n",
            "purchase hr and ndcg @10 : 0.005020, 0.002431\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 80.200000\n",
            "clicks hr ndcg @ 15 : 0.001889, 0.000876\n",
            "purchase hr and ndcg @15 : 0.006454, 0.002811\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 94.400000\n",
            "clicks hr ndcg @ 20 : 0.002196, 0.000948\n",
            "purchase hr and ndcg @20 : 0.007709, 0.003109\n",
            "#############################################################\n",
            "the loss in 8200th batch is: 8.091246\n",
            "the loss in 8400th batch is: 8.368961\n",
            "the loss in 8600th batch is: 8.435217\n",
            "the loss in 8800th batch is: 8.124487\n",
            "the loss in 9000th batch is: 8.479913\n",
            "the loss in 9200th batch is: 7.794878\n",
            "the loss in 9400th batch is: 8.167380\n",
            "the loss in 9600th batch is: 7.722779\n",
            "the loss in 9800th batch is: 8.090579\n",
            "the loss in 10000th batch is: 8.094834\n",
            "the loss in 10200th batch is: 7.955223\n",
            "the loss in 10400th batch is: 7.519062\n",
            "the loss in 10600th batch is: 7.400088\n",
            "the loss in 10800th batch is: 8.006672\n",
            "the loss in 11000th batch is: 7.528496\n",
            "the loss in 11200th batch is: 7.598825\n",
            "the loss in 11400th batch is: 7.803476\n",
            "the loss in 11600th batch is: 7.130460\n",
            "the loss in 11800th batch is: 7.502455\n",
            "the loss in 12000th batch is: 7.508162\n",
            "#############################################################\n",
            "total clicks: 117015, total purchase:5578\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 40.000000\n",
            "clicks hr ndcg @ 5 : 0.001068, 0.000561\n",
            "purchase hr and ndcg @5 : 0.002689, 0.001636\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 59.400000\n",
            "clicks hr ndcg @ 10 : 0.001555, 0.000717\n",
            "purchase hr and ndcg @10 : 0.004123, 0.002079\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 73.600000\n",
            "clicks hr ndcg @ 15 : 0.001906, 0.000810\n",
            "purchase hr and ndcg @15 : 0.005199, 0.002365\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 88.600000\n",
            "clicks hr ndcg @ 20 : 0.002290, 0.000903\n",
            "purchase hr and ndcg @20 : 0.006275, 0.002620\n",
            "#############################################################\n",
            "the loss in 12200th batch is: 7.361876\n",
            "the loss in 12400th batch is: 7.151054\n",
            "the loss in 12600th batch is: 7.459241\n",
            "the loss in 12800th batch is: 6.998973\n",
            "the loss in 13000th batch is: 7.485627\n",
            "the loss in 13200th batch is: 6.825167\n",
            "the loss in 13400th batch is: 7.347526\n",
            "the loss in 13600th batch is: 7.111711\n",
            "the loss in 13800th batch is: 7.040085\n",
            "the loss in 14000th batch is: 7.093768\n",
            "the loss in 14200th batch is: 7.323749\n",
            "the loss in 14400th batch is: 7.072322\n",
            "the loss in 14600th batch is: 7.384439\n",
            "the loss in 14800th batch is: 7.337852\n",
            "the loss in 15000th batch is: 7.066253\n",
            "the loss in 15200th batch is: 6.620472\n",
            "the loss in 15400th batch is: 6.444868\n",
            "the loss in 15600th batch is: 6.934052\n",
            "the loss in 15800th batch is: 6.966483\n",
            "the loss in 16000th batch is: 6.953797\n",
            "#############################################################\n",
            "total clicks: 117015, total purchase:5578\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 23.800000\n",
            "clicks hr ndcg @ 5 : 0.000718, 0.000540\n",
            "purchase hr and ndcg @5 : 0.001255, 0.001099\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 53.800000\n",
            "clicks hr ndcg @ 10 : 0.001316, 0.000735\n",
            "purchase hr and ndcg @10 : 0.004123, 0.002025\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 70.600000\n",
            "clicks hr ndcg @ 15 : 0.001778, 0.000856\n",
            "purchase hr and ndcg @15 : 0.005199, 0.002321\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 89.400000\n",
            "clicks hr ndcg @ 20 : 0.002282, 0.000975\n",
            "purchase hr and ndcg @20 : 0.006454, 0.002617\n",
            "#############################################################\n",
            "the loss in 16200th batch is: 7.068847\n",
            "the loss in 16400th batch is: 6.253593\n",
            "the loss in 16600th batch is: 6.942019\n",
            "the loss in 16800th batch is: 6.498193\n",
            "the loss in 17000th batch is: 6.396056\n",
            "the loss in 17200th batch is: 6.364209\n",
            "the loss in 17400th batch is: 6.909340\n",
            "the loss in 17600th batch is: 6.975301\n",
            "the loss in 17800th batch is: 6.489921\n",
            "the loss in 18000th batch is: 6.862474\n",
            "the loss in 18200th batch is: 6.616910\n",
            "the loss in 18400th batch is: 6.858563\n",
            "the loss in 18600th batch is: 6.333083\n",
            "the loss in 18800th batch is: 6.426126\n",
            "the loss in 19000th batch is: 6.440112\n",
            "the loss in 19200th batch is: 6.296867\n",
            "the loss in 19400th batch is: 7.001541\n",
            "the loss in 19600th batch is: 6.456355\n",
            "the loss in 19800th batch is: 6.618853\n",
            "the loss in 20000th batch is: 6.316472\n",
            "#############################################################\n",
            "total clicks: 117015, total purchase:5578\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 46.600000\n",
            "clicks hr ndcg @ 5 : 0.000795, 0.000529\n",
            "purchase hr and ndcg @5 : 0.005020, 0.003424\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 76.000000\n",
            "clicks hr ndcg @ 10 : 0.001410, 0.000722\n",
            "purchase hr and ndcg @10 : 0.007709, 0.004279\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 95.200000\n",
            "clicks hr ndcg @ 15 : 0.001803, 0.000826\n",
            "purchase hr and ndcg @15 : 0.009502, 0.004753\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 107.200000\n",
            "clicks hr ndcg @ 20 : 0.002145, 0.000907\n",
            "purchase hr and ndcg @20 : 0.010219, 0.004928\n",
            "#############################################################\n",
            "the loss in 20200th batch is: 6.181857\n",
            "the loss in 20400th batch is: 6.688447\n",
            "the loss in 20600th batch is: 6.487507\n",
            "the loss in 20800th batch is: 6.393498\n",
            "the loss in 21000th batch is: 6.195141\n",
            "the loss in 21200th batch is: 6.224562\n",
            "the loss in 21400th batch is: 6.450312\n",
            "the loss in 21600th batch is: 5.843682\n",
            "the loss in 21800th batch is: 6.369475\n",
            "the loss in 22000th batch is: 6.604534\n",
            "the loss in 22200th batch is: 6.207436\n",
            "the loss in 22400th batch is: 6.532252\n",
            "the loss in 22600th batch is: 6.600065\n",
            "the loss in 22800th batch is: 6.289104\n",
            "the loss in 23000th batch is: 6.003672\n",
            "the loss in 23200th batch is: 5.915475\n",
            "the loss in 23400th batch is: 5.979697\n",
            "the loss in 23600th batch is: 6.203243\n",
            "the loss in 23800th batch is: 5.945419\n",
            "the loss in 24000th batch is: 6.334566\n",
            "#############################################################\n",
            "total clicks: 117015, total purchase:5578\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 69.800000\n",
            "clicks hr ndcg @ 5 : 0.001316, 0.000871\n",
            "purchase hr and ndcg @5 : 0.006992, 0.004674\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 93.600000\n",
            "clicks hr ndcg @ 10 : 0.001991, 0.001085\n",
            "purchase hr and ndcg @10 : 0.008426, 0.005146\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 112.800000\n",
            "clicks hr ndcg @ 15 : 0.002470, 0.001211\n",
            "purchase hr and ndcg @15 : 0.009860, 0.005520\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 132.800000\n",
            "clicks hr ndcg @ 20 : 0.002940, 0.001322\n",
            "purchase hr and ndcg @20 : 0.011474, 0.005901\n",
            "#############################################################\n",
            "the loss in 24200th batch is: 6.304115\n",
            "the loss in 24400th batch is: 6.045940\n",
            "the loss in 24600th batch is: 6.296544\n",
            "the loss in 24800th batch is: 6.160001\n",
            "the loss in 25000th batch is: 6.445512\n",
            "the loss in 25200th batch is: 5.720465\n",
            "the loss in 25400th batch is: 6.424493\n",
            "the loss in 25600th batch is: 6.013284\n",
            "the loss in 25800th batch is: 5.481521\n",
            "the loss in 26000th batch is: 6.194191\n",
            "the loss in 26200th batch is: 6.448557\n",
            "the loss in 26400th batch is: 6.268465\n",
            "the loss in 26600th batch is: 5.693542\n",
            "the loss in 26800th batch is: 5.926187\n",
            "the loss in 27000th batch is: 6.275767\n",
            "the loss in 27200th batch is: 5.866310\n",
            "the loss in 27400th batch is: 5.980810\n",
            "the loss in 27600th batch is: 5.626760\n",
            "the loss in 27800th batch is: 5.888254\n",
            "the loss in 28000th batch is: 5.961091\n",
            "#############################################################\n",
            "total clicks: 117015, total purchase:5578\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 45.000000\n",
            "clicks hr ndcg @ 5 : 0.001068, 0.000695\n",
            "purchase hr and ndcg @5 : 0.003586, 0.002537\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 76.000000\n",
            "clicks hr ndcg @ 10 : 0.001752, 0.000918\n",
            "purchase hr and ndcg @10 : 0.006275, 0.003390\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 98.800000\n",
            "clicks hr ndcg @ 15 : 0.002384, 0.001085\n",
            "purchase hr and ndcg @15 : 0.007709, 0.003763\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 117.000000\n",
            "clicks hr ndcg @ 20 : 0.002820, 0.001187\n",
            "purchase hr and ndcg @20 : 0.009143, 0.004102\n",
            "#############################################################\n",
            "the loss in 28200th batch is: 5.536285\n",
            "the loss in 28400th batch is: 5.512068\n",
            "the loss in 28600th batch is: 5.773077\n",
            "the loss in 28800th batch is: 6.343480\n",
            "the loss in 29000th batch is: 6.332885\n",
            "the loss in 29200th batch is: 5.980138\n",
            "the loss in 29400th batch is: 6.072054\n",
            "the loss in 29600th batch is: 5.969283\n",
            "the loss in 29800th batch is: 5.301534\n",
            "the loss in 30000th batch is: 6.192428\n",
            "the loss in 30200th batch is: 5.338637\n",
            "the loss in 30400th batch is: 5.532771\n",
            "the loss in 30600th batch is: 5.627290\n",
            "the loss in 30800th batch is: 5.944642\n",
            "the loss in 31000th batch is: 5.619929\n",
            "the loss in 31200th batch is: 6.035815\n",
            "the loss in 31400th batch is: 5.683254\n",
            "the loss in 31600th batch is: 5.799957\n",
            "the loss in 31800th batch is: 5.543540\n",
            "the loss in 32000th batch is: 5.677729\n",
            "#############################################################\n",
            "total clicks: 117015, total purchase:5578\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 55.800000\n",
            "clicks hr ndcg @ 5 : 0.001188, 0.000844\n",
            "purchase hr and ndcg @5 : 0.005020, 0.003781\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 89.800000\n",
            "clicks hr ndcg @ 10 : 0.001872, 0.001060\n",
            "purchase hr and ndcg @10 : 0.008247, 0.004806\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 118.000000\n",
            "clicks hr ndcg @ 15 : 0.002436, 0.001210\n",
            "purchase hr and ndcg @15 : 0.010936, 0.005517\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 137.400000\n",
            "clicks hr ndcg @ 20 : 0.002837, 0.001304\n",
            "purchase hr and ndcg @20 : 0.012729, 0.005934\n",
            "#############################################################\n",
            "the loss in 32200th batch is: 6.153173\n",
            "the loss in 32400th batch is: 5.852957\n",
            "the loss in 32600th batch is: 5.278210\n",
            "the loss in 32800th batch is: 5.782992\n",
            "the loss in 33000th batch is: 5.416060\n",
            "the loss in 33200th batch is: 5.747553\n",
            "the loss in 33400th batch is: 5.274882\n",
            "the loss in 33600th batch is: 5.657783\n",
            "the loss in 33800th batch is: 5.589919\n",
            "the loss in 34000th batch is: 5.724279\n",
            "the loss in 34200th batch is: 6.233144\n",
            "the loss in 34400th batch is: 5.964678\n",
            "the loss in 34600th batch is: 5.535116\n",
            "the loss in 34800th batch is: 5.659423\n",
            "the loss in 35000th batch is: 6.281260\n",
            "the loss in 35200th batch is: 5.570106\n",
            "the loss in 35400th batch is: 5.749250\n",
            "the loss in 35600th batch is: 5.540656\n",
            "the loss in 35800th batch is: 5.994585\n",
            "the loss in 36000th batch is: 5.698658\n",
            "the loss in 36200th batch is: 5.234161\n",
            "the loss in 36400th batch is: 5.785852\n",
            "the loss in 36600th batch is: 5.695652\n",
            "the loss in 36800th batch is: 5.766479\n",
            "the loss in 37000th batch is: 5.034527\n",
            "the loss in 37200th batch is: 5.367808\n",
            "the loss in 37400th batch is: 5.811238\n",
            "the loss in 37600th batch is: 5.793285\n",
            "the loss in 37800th batch is: 5.593441\n",
            "the loss in 38000th batch is: 5.766139\n",
            "the loss in 38200th batch is: 5.695933\n",
            "the loss in 38400th batch is: 5.528609\n"
          ]
        }
      ]
    }
  ]
}